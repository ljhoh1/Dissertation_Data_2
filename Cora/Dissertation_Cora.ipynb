{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-G88EgqsOtlZ"
   },
   "source": [
    "# Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ifVsU9T740xo",
    "outputId": "44e86c9a-0172-41b6-8591-b54863a45854"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Verify pandas==1.2.4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/sklearn/externals/six.py:31: FutureWarning: The module is deprecated in version 0.21 and will be removed in version 0.23 since we've dropped support for Python 2.7. Please rely on the official version of six (https://pypi.org/project/six/).\n",
      "  \"(https://pypi.org/project/six/).\", FutureWarning)\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/utils/deprecation.py:144: FutureWarning: The sklearn.neighbors.base module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.neighbors. Anything that cannot be imported from sklearn.neighbors is now part of the private API.\n",
      "  warnings.warn(message, FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "import scipy as sp\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn as sk\n",
    "from collections import defaultdict\n",
    "\n",
    "try:\n",
    "    import py_entitymatching as em\n",
    "except:\n",
    "    !pip install py_entitymatching\n",
    "\n",
    "try:\n",
    "    import deepmatcher as dm\n",
    "except:\n",
    "    !pip uninstall preprocessing -y\n",
    "    !pip uninstall fastai -y \n",
    "    !pip uninstall allennlp -y\n",
    "    !pip install deepmatcher\n",
    "\n",
    "if pd.__version__ != \"1.2.4\":\n",
    " !pip install pandas==1.2.4\n",
    " import pandas as pd\n",
    " print(f\"Verify pandas=={pd.__version__}\")\n",
    "else:\n",
    " print(f\"Verify pandas=={pd.__version__}\")\n",
    "\n",
    "import sys\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.client import device_lib\n",
    "import os\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "71h_YawK49Tx",
    "outputId": "13dff907-8fd8-4815-89df-1077cc479a4e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'Dissertation_Data_2'...\n",
      "remote: Enumerating objects: 92, done.\u001b[K\n",
      "remote: Counting objects: 100% (92/92), done.\u001b[K\n",
      "remote: Compressing objects: 100% (64/64), done.\u001b[K\n",
      "remote: Total 92 (delta 38), reused 80 (delta 28), pack-reused 0\u001b[K\n",
      "Unpacking objects: 100% (92/92), done.\n",
      "Checking out files: 100% (36/36), done.\n"
     ]
    }
   ],
   "source": [
    "! git clone https://github.com/ljhoh1/Dissertation_Data_2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tbluBd55OrgN"
   },
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-Mw0cgFN4_XW",
    "outputId": "f66cc0ad-7efe-4078-8803-322990945467"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:py_entitymatching.io.parsers:Metadata file is not present in the given path; proceeding to read the csv file.\n"
     ]
    }
   ],
   "source": [
    "path_Match_Cora = os.path.join('.', 'Dissertation_Data_2', 'cora_duplicates_data.tsv')\n",
    "labelled_Cora = em.read_csv_metadata(path_Match_Cora)\n",
    "\n",
    "path_Cora = os.path.join('.', 'Dissertation_Data_2', 'cora_data.tsv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kSYo95EK5JFZ",
    "outputId": "4cee841c-d4cf-49df-dbd1-8663c0852f42"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:py_entitymatching.io.parsers:Metadata file is not present in the given path; proceeding to read the csv file.\n"
     ]
    }
   ],
   "source": [
    "# Cora data\n",
    "csv_table=pd.read_table(path_Cora,sep='\\t')\n",
    "csv_table.to_csv(os.path.join('.', 'Dissertation_Data_2', 'cora_data.csv'),index=False)\n",
    "Cora = em.read_csv_metadata(os.path.join('.', 'Dissertation_Data_2', 'cora_data.csv'), key='id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qewOWu82kAry",
    "outputId": "0df92b02-a21e-4d0c-dcc7-2a9cc2175351"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "address        1139\n",
       "authors           3\n",
       "booktitle       974\n",
       "date           1374\n",
       "editor         1422\n",
       "id                0\n",
       "institution    1631\n",
       "journal        1244\n",
       "month          1849\n",
       "note           1807\n",
       "pages           643\n",
       "publisher      1173\n",
       "tech           1729\n",
       "title            41\n",
       "type           1766\n",
       "volume         1044\n",
       "year            654\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Cora.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Nr3q2JFg5NRb",
    "outputId": "81133199-41b0-4535-87ed-1a3e4a421d26"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:2: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  \n",
      "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:7: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  import sys\n"
     ]
    }
   ],
   "source": [
    "for col in Cora.columns:\n",
    "  Cora[col] = Cora[col].astype(str).str.replace('[^A-Za-z0-9 ]+', '')\n",
    "  #Cora = Cora.str.replace('[^A-Za-z0-9 ]+', '')\n",
    "  Cora[col] = Cora[col].astype(str).str.lower()\n",
    "  #Cora.loc[Cora[col] == 'nan', [col]] = np.nan\n",
    "Cora.head()\n",
    "Cora['date'] = Cora['date'].astype(str).str.replace('[^0-9]+', '')\n",
    "#Cora['yea'] = Cora['year']\n",
    "Cora.year.fillna(Cora.date, inplace=True)\n",
    "Cora.loc[Cora['year'] == '', ['year']] = np.nan\n",
    "#del Cora['date']\n",
    "del Cora['date']\n",
    "\n",
    "Cora.rename(columns = {'type':'new_type'}, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YPLwjAZnOo0A"
   },
   "source": [
    "# Blocking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "ggrsMGIm5RZd"
   },
   "outputs": [],
   "source": [
    "# Blocking - Cora/Cora\n",
    "# Get tokenizers and similarity function\n",
    "block_t = em.get_tokenizers_for_blocking()\n",
    "block_s = em.get_sim_funs_for_blocking()\n",
    "\n",
    "# Get attributes\n",
    "atypes1 = em.get_attr_types(Cora)\n",
    "atypes2 = em.get_attr_types(Cora)\n",
    "\n",
    "# Get correspondence\n",
    "block_c = em.get_attr_corres(Cora, Cora)\n",
    "\n",
    "#Get Features\n",
    "block_f = em.get_features(Cora, Cora, atypes1, atypes2, block_c, block_t, block_s)\n",
    "\n",
    "cols_cora = [i for i in Cora.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xC6xXg1f5dQ9",
    "outputId": "066bd4cb-7074-427d-9eac-8e29c07a31d9"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0% [##############################] 100% | ETA: 00:00:00\n",
      "Total time elapsed: 00:00:02\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finding pairs with missing value...\n"
     ]
    }
   ],
   "source": [
    "# Creating a rule based blocker\n",
    "rb = em.RuleBasedBlocker()\n",
    "\n",
    "cols_cora = [i for i in Cora.columns]\n",
    "rule = ['title_title_jac_qgm_3_qgm_3(ltuple, rtuple) < 0.35']\n",
    "rb.add_rule(rule, feature_table=block_f)\n",
    "K4 = rb.block_tables(Cora, Cora,\n",
    "                   l_output_attrs=cols_cora, \n",
    "                   r_output_attrs=cols_cora,\n",
    "                   n_jobs=1)\n",
    "\n",
    "# Creating a rule based blocker\n",
    "#rb = em.RuleBasedBlocker()\n",
    "\n",
    "#rule = ['authors_authors_jac_qgm_3_qgm_3(ltuple, rtuple) < 0.1']\n",
    "#rb.add_rule(rule, feature_table=block_f)\n",
    "#K4 = rb.block_candset(K3, n_jobs=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dJ07PLiHOlNP"
   },
   "source": [
    "# Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "eO5a62Zq5lgX"
   },
   "outputs": [],
   "source": [
    "def labelling(train, labelled, key = \"idDBLP\", val = \"idScholar\"):\n",
    "  '''\n",
    "  Create dictionary for checking how many matches are retained and perform labelling\n",
    "  Input:\n",
    "  - train (pd.DataFrame): DataFrame object of blocked data used for training\n",
    "  - lbelled (pd.DataFrame): The labelled DataFrame for labelling the train data\n",
    "  - key (string): which table id in blocked \"train\" to use as key for labelling\n",
    "  - val (string): which table id in blocked \"train\" to use as value for labelling\n",
    "  Output:\n",
    "  - train (pd.DataFrame): The labelled training dataframe\n",
    "  '''\n",
    "  train[\"id_comb\"] = train[\"rtable_id\"].astype(str) + train[\"ltable_id\"].astype(str)\n",
    "  labelled[\"id_comb\"] = labelled[key].astype(str) + labelled[val].astype(str)\n",
    "\n",
    "  K = train.merge(labelled, on='id_comb', how='left', indicator=True)\n",
    "  K.loc[(K['_merge'] == \"both\"), 'label'] = 1\n",
    "  K.loc[(K['_merge'] == \"left_only\") | (K['_merge'] == \"right_only\"), 'label'] = 0\n",
    "  del K['_merge']\n",
    "  del K['id1']\n",
    "  del K['id2']\n",
    "  del K['id_comb']\n",
    "  return K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "II5U364ZOjtW"
   },
   "outputs": [],
   "source": [
    "def scores(time, predictions, iteration, train_n, model, epochs=15):\n",
    "  '''\n",
    "  Report the most important metrics of performance from the predictions made by the model\n",
    "  Input:\n",
    "  - time (float): time the model ran for\n",
    "  - predictions (pd.DataFrame): contains the output features and column \"match_score\", containing the prediction information\n",
    "  - iteration (int64): the current iteration if applicable\n",
    "  - train_n (int64): the number of samples used in training\n",
    "  - model (string): the model that was used\n",
    "  - epochs (int64): the number of epochs the model was trained for\n",
    "  Output:\n",
    "  - dict (dictionary): dictionary containing the performance information  \n",
    "  '''\n",
    "  # casting prediction scores as binary labels\n",
    "  predictions['match_prediction'] = predictions['match_score'].apply(lambda score: 1 if score >= 0.5 else 0)\n",
    "  # Reset index as Magellan requires the key to be a column in the table\n",
    "  predictions.reset_index(inplace=True)\n",
    "  # Update metadata in the catalog. This information can later be used by triggers to modify the labels from \n",
    "  # the learning-based matcher \n",
    "  em.set_key(predictions, '_id')\n",
    "  em.set_fk_ltable(predictions, 'ltable_id')\n",
    "  em.set_fk_rtable(predictions, 'rtable_id')\n",
    "  # AUC-ROC metrics\n",
    "  auc = sk.metrics.roc_auc_score(predictions['label'], predictions['match_prediction'], average = None)\n",
    "  # Precision Metrics\n",
    "  prec = em.eval_matches(predictions, 'label', 'match_prediction')\n",
    "  # Creating dictionary of performance metrics to append to a DataFrame\n",
    "  dict = {'Model':model, 'Time':time, 'Epochs':epochs,'Iteration':iteration, '#Training_samples':train_n,\n",
    "                          'F1':prec['f1'], 'Precision':prec['precision'], \n",
    "                          'Recall':prec['recall'], 'AUC':auc}\n",
    "  return dict\n",
    "# Create a placeholder matrix to append precision scores to\n",
    "prec_matrix = pd.DataFrame(columns=['Model', 'Time', 'Epochs', 'Iteration', '#Training_samples', 'F1', 'Precision', 'Recall', 'AUC'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "hTIR1nsTjbdY"
   },
   "outputs": [],
   "source": [
    "def subsampling(cand):\n",
    "  '''\n",
    "  Function to subsample to avoid unbalanced data\n",
    "  Input:\n",
    "  - cand (pd.DataFrame): contains the blocked (and transformed) data with \"label\" feature\n",
    "  Output:\n",
    "  - cand_resampled (pd.DataFrame): contains the resampled data to avoid imbalance\n",
    "  '''\n",
    "  # subsampling the candidate set for better balance\n",
    "  # creating the explanatory and dependent feature data\n",
    "  binary_X = cand.loc[:, cand.columns != \"label\"]\n",
    "  binary_y = cand.loc[:, cand.columns == \"label\"]\n",
    "  # initialising the RandomUnderSampler\n",
    "  rus = RandomUnderSampler(random_state=0)\n",
    "  # resampling to 0.5/0.5\n",
    "  X_res, y_res = rus.fit_resample(binary_X, binary_y)\n",
    "  res_labelled = pd.DataFrame(X_res)\n",
    "  res_labelled.columns = cand.columns[0:-1]\n",
    "  # take the index of resampled observations to subsample from the original\n",
    "  sel_idx = list(res_labelled._id)\n",
    "  cand_resampled = cand[cand[\"_id\"].isin(sel_idx)]\n",
    "  return cand_resampled"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "r2pB1GxNO1zl"
   },
   "source": [
    "# Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QoZ7cmIn5nUH",
    "outputId": "ae6651df-0040-4b77-9d0c-3d8dba49b186"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:py_entitymatching.io.parsers:Metadata file is not present in the given path; proceeding to read the csv file.\n"
     ]
    }
   ],
   "source": [
    "# The path to the labeled data file.\n",
    "csv_table=pd.read_table(path_Match_Cora, sep='\\t')\n",
    "csv_table.to_csv(os.path.join('.', 'Dissertation_Data_2', 'cora_labelled.csv'),index=False)\n",
    "cora_labelled = em.read_csv_metadata(os.path.join('.', 'Dissertation_Data_2', 'cora_labelled.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "CGu0RNcbTSrh"
   },
   "outputs": [],
   "source": [
    "cols = list(cora_labelled.columns)\n",
    "a, b = cols.index('id1'), cols.index('id2')\n",
    "cols[b], cols[a] = cols[a], cols[b]\n",
    "cor_lab_rev = cora_labelled[cols]\n",
    "cor_lab_rev.columns = ['id1', 'id2']\n",
    "cora_labelled = cora_labelled.append(cor_lab_rev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "B1L0cKcS5pfM",
    "outputId": "a54c4a95-61c9-4654-f6fa-94d3a878597e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Proportion of matches retained after blocking: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:8: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "# Labelling the blocked data set\n",
    "cand = labelling(K4, cora_labelled, key = \"id1\", val = \"id2\")\n",
    "print(\"Proportion of matches retained after blocking:\", round(sum(cand['label']) / cora_labelled.shape[0], 2))\n",
    "\n",
    "# subsampling the candidate set for better balance\n",
    "for col in cand.columns:\n",
    "    if col != \"_id\" and col != \"label\":\n",
    "      cand[col] = cand[col].astype(str).str.replace('[^A-Za-z0-9 ]+', '')\n",
    "    else:\n",
    "      cand[col] = cand[col].astype(int)\n",
    "\n",
    "#cand = cand.sample(frac=0.5, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AshNssGUQLsS",
    "outputId": "2e0bd6e0-95de-4396-867f-5118f23b95e7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(129156, 3)"
      ]
     },
     "execution_count": 16,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cora_labelled.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lENend5UL2vb",
    "outputId": "3db4bb53-e9b0-4f4b-c09a-2ac17b6643e7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "129102"
      ]
     },
     "execution_count": 17,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(cand['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "y4bKrSff5rtg"
   },
   "outputs": [],
   "source": [
    "# The directory where the data splits will be saved.\n",
    "split_path = os.path.join('.', 'Dissertation_Data_2')\n",
    "# Split labeled data into train, valid, and test csv files to disk, with the split ratio of 3:1:1.\n",
    "dm.data.split(cand, split_path, 'train.csv', 'valid.csv', 'test.csv',\n",
    "              [3, 1, 1],\n",
    "              stratified=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "85ROG_80b6DY"
   },
   "outputs": [],
   "source": [
    "#train_tosub = em.read_csv_metadata(os.path.join('.', 'Dissertation_Data_2', 'train.csv'))\n",
    "\n",
    "#cand_resampled = train_tosub.sample(frac=0.6, random_state=1)\n",
    "#cand_resampled.to_csv(os.path.join('.', 'Dissertation_Data_2', 'train.csv'),index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Y9-lRVe_qc-O",
    "outputId": "5b1b30e9-c3c2-4313-93d3-5e02d536035b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Proportion of matches retained after blocking: 0.62\n"
     ]
    }
   ],
   "source": [
    "print(\"Proportion of matches retained after blocking:\", round(sum(cand['label']) / cand.shape[0], 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gGV2dsjC5w-G",
    "outputId": "89040bcc-5430-4ea8-ab70-763f45f7a335"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Reading and processing data from \"./Dissertation_Data_2/train.csv\"\n",
      "0% [##############################] 100% | ETA: 00:00:00\n",
      "Reading and processing data from \"./Dissertation_Data_2/valid.csv\"\n",
      "0% [##############################] 100% | ETA: 00:00:00\n",
      "Reading and processing data from \"./Dissertation_Data_2/test.csv\"\n",
      "0% [##############################] 100% | ETA: 00:00:00INFO:deepmatcher.data.field:Downloading vectors from https://drive.google.com/uc?export=download&id=1Vih8gAmgBnuYDxfblbT94P6WjB7s1ZSh to /root/.vector_cache/wiki.en.bin\n",
      "wiki.en.bin: 8.49GB [01:29, 94.8MB/s]\n",
      "INFO:deepmatcher.data.field:Extracting vectors into /root/.vector_cache\n",
      "Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\n",
      "\n",
      "Building vocabulary\n",
      "0% [##############################] 100% | ETA: 00:00:00\n",
      "Total time elapsed: 00:00:22\n",
      "\n",
      "Computing principal components\n",
      "0% [##############################] 100% | ETA: 00:00:00\n",
      "Total time elapsed: 00:01:59\n"
     ]
    }
   ],
   "source": [
    "# Load the training data files from the disk. Ignore the \"left_id\" and \"right_id\" \n",
    "# columns for data preprocessing.\n",
    "# The 'use_magellan_convention' parameter asks deepmatcher to use Magellan's \n",
    "# naming convention for the left and right table column name prefixes \n",
    "# (\"ltable_\", and \"rtable_\"), and also to consider \"_id\" as the ID column.\n",
    "train, validation, test = dm.data.process(\n",
    "    path=os.path.join('.', 'Dissertation_Data_2'),\n",
    "    cache='train_cache.pth',\n",
    "    train='train.csv',\n",
    "    validation='valid.csv',\n",
    "    test='test.csv',\n",
    "    use_magellan_convention=True,\n",
    "    ignore_columns=('ltable_id', 'rtable_id'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OemKUPj4O8Cz"
   },
   "source": [
    "# Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZUMvyDaFPH7E"
   },
   "source": [
    "## DL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Cm2QXZn16-zJ"
   },
   "source": [
    "### Sif-Diff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EQ8qYHQ65zqm",
    "outputId": "21607a4f-a92e-4297-d06d-0bf6151d51ff"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py:974: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
      "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Number of trainable parameters: 1083302\n",
      "===>  TRAIN Epoch 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2742: UserWarning: reduction: 'mean' divides the total loss by both the batch size and the support size.'batchmean' divides only by the batch size, and aligns with the KL div math definition.'mean' will be changed to behave the same as 'batchmean' in the next major release.\n",
      "  \"reduction: 'mean' divides the total loss by both the batch size and the support size.\"\n",
      "0% [██████████████████████████████] 100% | ETA: 00:00:00\n",
      "Total time elapsed: 00:09:18\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Epoch 1 || Run Time:   52.4 | Load Time:  508.3 || F1:  97.38 | Prec:  95.20 | Rec:  99.67 || Ex/s: 222.13\n",
      "\n",
      "===>  EVAL Epoch 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0% [██████████████████████████████] 100% | ETA: 00:00:00\n",
      "Total time elapsed: 00:02:56\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Epoch 1 || Run Time:   12.1 | Load Time:  164.1 || F1:  99.25 | Prec:  98.52 | Rec:  99.99 || Ex/s: 235.61\n",
      "\n",
      "* Best F1: tensor(99.2504, device='cuda:0')\n",
      "Saving best model...\n",
      "Done.\n",
      "---------------------\n",
      "\n",
      "===>  TRAIN Epoch 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0% [██████████████████████████████] 100% | ETA: 00:00:00\n",
      "Total time elapsed: 00:09:21\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Epoch 2 || Run Time:   52.6 | Load Time:  510.8 || F1:  99.24 | Prec:  98.52 | Rec:  99.97 || Ex/s: 221.08\n",
      "\n",
      "===>  EVAL Epoch 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0% [██████████████████████████████] 100% | ETA: 00:00:00\n",
      "Total time elapsed: 00:02:55\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Epoch 2 || Run Time:   12.1 | Load Time:  163.8 || F1:  99.26 | Prec:  98.54 | Rec:  99.99 || Ex/s: 236.08\n",
      "\n",
      "* Best F1: tensor(99.2599, device='cuda:0')\n",
      "Saving best model...\n",
      "Done.\n",
      "---------------------\n",
      "\n",
      "===>  TRAIN Epoch 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0% [██████████████████████████████] 100% | ETA: 00:00:00\n",
      "Total time elapsed: 00:09:17\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Epoch 3 || Run Time:   52.0 | Load Time:  507.5 || F1:  99.26 | Prec:  98.54 | Rec:  99.98 || Ex/s: 222.65\n",
      "\n",
      "===>  EVAL Epoch 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0% [██████████████████████████████] 100% | ETA: 00:00:00\n",
      "Total time elapsed: 00:02:54\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Epoch 3 || Run Time:   12.0 | Load Time:  162.9 || F1:  99.27 | Prec:  98.55 | Rec:  99.99 || Ex/s: 237.41\n",
      "\n",
      "* Best F1: tensor(99.2656, device='cuda:0')\n",
      "Saving best model...\n",
      "Done.\n",
      "---------------------\n",
      "\n",
      "===>  TRAIN Epoch 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0% [██████████████████████████████] 100% | ETA: 00:00:00\n",
      "Total time elapsed: 00:09:18\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Epoch 4 || Run Time:   52.0 | Load Time:  508.8 || F1:  99.26 | Prec:  98.54 | Rec:  99.99 || Ex/s: 222.14\n",
      "\n",
      "===>  EVAL Epoch 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0% [██████████████████████████████] 100% | ETA: 00:00:00\n",
      "Total time elapsed: 00:02:55\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Epoch 4 || Run Time:   12.1 | Load Time:  163.5 || F1:  99.27 | Prec:  98.56 | Rec:  99.99 || Ex/s: 236.45\n",
      "\n",
      "* Best F1: tensor(99.2695, device='cuda:0')\n",
      "Saving best model...\n",
      "Done.\n",
      "---------------------\n",
      "\n",
      "===>  TRAIN Epoch 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0% [██████████████████████████████] 100% | ETA: 00:00:00\n",
      "Total time elapsed: 00:09:19\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Epoch 5 || Run Time:   52.2 | Load Time:  509.6 || F1:  99.26 | Prec:  98.55 | Rec:  99.99 || Ex/s: 221.71\n",
      "\n",
      "===>  EVAL Epoch 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0% [██████████████████████████████] 100% | ETA: 00:00:00\n",
      "Total time elapsed: 00:02:53\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Epoch 5 || Run Time:   11.9 | Load Time:  162.0 || F1:  99.27 | Prec:  98.56 | Rec:  99.99 || Ex/s: 238.84\n",
      "\n",
      "---------------------\n",
      "\n",
      "===>  TRAIN Epoch 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0% [██████████████████████████████] 100% | ETA: 00:00:00\n",
      "Total time elapsed: 00:09:19\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Epoch 6 || Run Time:   52.3 | Load Time:  509.7 || F1:  99.26 | Prec:  98.55 | Rec:  99.99 || Ex/s: 221.64\n",
      "\n",
      "===>  EVAL Epoch 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0% [██████████████████████████████] 100% | ETA: 00:00:00\n",
      "Total time elapsed: 00:02:54\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Epoch 6 || Run Time:   12.0 | Load Time:  162.7 || F1:  99.27 | Prec:  98.56 | Rec:  99.99 || Ex/s: 237.76\n",
      "\n",
      "---------------------\n",
      "\n",
      "===>  TRAIN Epoch 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0% [██████████████████████████████] 100% | ETA: 00:00:00\n",
      "Total time elapsed: 00:09:13\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Epoch 7 || Run Time:   51.5 | Load Time:  504.4 || F1:  99.26 | Prec:  98.55 | Rec:  99.99 || Ex/s: 224.09\n",
      "\n",
      "===>  EVAL Epoch 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0% [██████████████████████████████] 100% | ETA: 00:00:00\n",
      "Total time elapsed: 00:02:52\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Epoch 7 || Run Time:   11.8 | Load Time:  161.0 || F1:  99.27 | Prec:  98.56 | Rec:  99.99 || Ex/s: 240.31\n",
      "\n",
      "---------------------\n",
      "\n",
      "===>  TRAIN Epoch 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0% [██████████████████████████████] 100% | ETA: 00:00:00\n",
      "Total time elapsed: 00:09:07\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Epoch 8 || Run Time:   50.5 | Load Time:  499.4 || F1:  99.26 | Prec:  98.55 | Rec:  99.99 || Ex/s: 226.53\n",
      "\n",
      "===>  EVAL Epoch 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0% [██████████████████████████████] 100% | ETA: 00:00:00\n",
      "Total time elapsed: 00:02:51\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Epoch 8 || Run Time:   11.7 | Load Time:  159.9 || F1:  99.27 | Prec:  98.56 | Rec:  99.98 || Ex/s: 242.00\n",
      "\n",
      "---------------------\n",
      "\n",
      "===>  TRAIN Epoch 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0% [██████████████████████████████] 100% | ETA: 00:00:00\n",
      "Total time elapsed: 00:09:06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Epoch 9 || Run Time:   50.3 | Load Time:  498.9 || F1:  99.26 | Prec:  98.55 | Rec:  99.99 || Ex/s: 226.78\n",
      "\n",
      "===>  EVAL Epoch 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0% [██████████████████████████████] 100% | ETA: 00:00:00\n",
      "Total time elapsed: 00:02:52\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Epoch 9 || Run Time:   11.8 | Load Time:  160.6 || F1:  99.27 | Prec:  98.56 | Rec:  99.98 || Ex/s: 240.83\n",
      "\n",
      "---------------------\n",
      "\n",
      "===>  TRAIN Epoch 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0% [██████████████████████████████] 100% | ETA: 00:00:00\n",
      "Total time elapsed: 00:09:11\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Epoch 10 || Run Time:   51.1 | Load Time:  502.8 || F1:  99.26 | Prec:  98.55 | Rec:  99.99 || Ex/s: 224.88\n",
      "\n",
      "===>  EVAL Epoch 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0% [██████████████████████████████] 100% | ETA: 00:00:00\n",
      "Total time elapsed: 00:02:51\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Epoch 10 || Run Time:   11.7 | Load Time:  159.8 || F1:  99.27 | Prec:  98.56 | Rec:  99.98 || Ex/s: 242.20\n",
      "\n",
      "---------------------\n",
      "\n",
      "Loading best model...\n",
      "Training done.\n",
      "===>  EVAL Epoch 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0% [██████████████████████████████] 100% | ETA: 00:00:00\n",
      "Total time elapsed: 00:03:03\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Epoch 4 || Run Time:   48.6 | Load Time:  135.0 || F1:  99.25 | Prec:  98.51 | Rec: 100.00 || Ex/s: 226.18\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(99.2504, device='cuda:0')"
      ]
     },
     "execution_count": 22,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a sifDiff model.\n",
    "model_sifdiff = dm.MatchingModel(attr_summarizer='sif')\n",
    "model_sifdiff.initialize(train)  # Initilization\n",
    "\n",
    "# Train ing model on 15 epochs, batch size of 16, positive-to-negative \n",
    "# ratio to be 1:1. We save the best model (with the \n",
    "# highest F1 score on the validation set) to 'sifDiff_model.pth'\n",
    "startTime = time.time()\n",
    "model_sifdiff.run_train(\n",
    "    train,\n",
    "    validation,\n",
    "    epochs=10,\n",
    "    batch_size=128,\n",
    "    best_save_path='sifDiff_model.pth',\n",
    "    pos_neg_ratio=2)\n",
    "executionTime_sifDiff = (time.time() - startTime)/60\n",
    "\n",
    "# Evaluate the accuracy on the test data.\n",
    "model_sifdiff.run_eval(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JQo-3uVuCJFt",
    "outputId": "3de71f17-0799-465c-9afe-e0983a7f3b99"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===>  PREDICT Epoch 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0% [██████████████████████████████] 100% | ETA: 00:00:00\n",
      "Total time elapsed: 00:03:01\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Epoch 4 || Run Time:   49.3 | Load Time:  132.9 || F1:  99.25 | Prec:  98.51 | Rec: 100.00 || Ex/s: 227.91\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Load the model.\n",
    "model_sifdiff = dm.MatchingModel(attr_summarizer='sif')\n",
    "model_sifdiff.load_state('sifDiff_model.pth')\n",
    "# Load the candidate set. Note that the trained model is an input parameter as we need to trained \n",
    "# model for candidate set preprocessing.\n",
    "predictions_sifDiff = model_sifdiff.run_prediction(test, output_attributes=list(test.get_raw_table().columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Vlt0C4xboHlF",
    "outputId": "08c78301-a2d5-4b8f-c102-7042d47ed845"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:py_entitymatching.io.parsers:Metadata file is not present in the given path; proceeding to read the csv file.\n"
     ]
    }
   ],
   "source": [
    "# get training data set and compute performance scores\n",
    "train_n = em.read_csv_metadata(os.path.join('.', 'Dissertation_Data_2', 'train.csv'))\n",
    "score_sifDiff = scores(executionTime_sifDiff, predictions_sifDiff, 0, train_n.shape[0], model = 'sif_diff')\n",
    "prec_matrix = prec_matrix.append(score_sifDiff, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "HII5X2GF7H1G"
   },
   "outputs": [],
   "source": [
    "high_score_pairs = predictions_sifDiff[predictions_sifDiff['match_score'] >= 0.9].sort_values(by=['match_score'], ascending=False)\n",
    "\n",
    "predictions_sifDiff['match_prediction'] = predictions_sifDiff['match_score'].apply(lambda score: 1 if score >= 0.5 else 0)\n",
    "# Reorder columns to avoid scrolling...\n",
    "predictions_sifDiff =  predictions_sifDiff[['match_score', 'match_prediction'] + predictions_sifDiff.columns.values[1:-1].tolist()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "ROPOFd2_KPrK"
   },
   "outputs": [],
   "source": [
    "path_predictions = os.path.join('.', 'Dissertation_Data_2', 'predictions_sifDiff.csv')\n",
    "predictions_sifDiff.to_csv(path_predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ix7Jd2Jg7dfZ"
   },
   "source": [
    "### RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lPFO8uVC7e5V",
    "outputId": "69d322ec-4213-4acc-ff8f-3fbaf818f64a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Number of trainable parameters: 7185302\n",
      "===>  TRAIN Epoch 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py:949: UserWarning: Using non-full backward hooks on a Module that does not take as input a single Tensor or a tuple of Tensors is deprecated and will be removed in future versions. This hook will be missing some of the grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
      "  warnings.warn(\"Using non-full backward hooks on a Module that does not take as input a \"\n",
      "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py:974: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
      "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n",
      "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py:939: UserWarning: Using non-full backward hooks on a Module that does not return a single Tensor or a tuple of Tensors is deprecated and will be removed in future versions. This hook will be missing some of the grad_output. Please use register_full_backward_hook to get the documented behavior.\n",
      "  warnings.warn(\"Using non-full backward hooks on a Module that does not return a \"\n",
      "/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2742: UserWarning: reduction: 'mean' divides the total loss by both the batch size and the support size.'batchmean' divides only by the batch size, and aligns with the KL div math definition.'mean' will be changed to behave the same as 'batchmean' in the next major release.\n",
      "  \"reduction: 'mean' divides the total loss by both the batch size and the support size.\"\n",
      "0% [██████████████████████████████] 100% | ETA: 00:00:00\n",
      "Total time elapsed: 00:11:14\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Epoch 1 || Run Time:  120.0 | Load Time:  557.2 || F1:  98.85 | Prec:  97.92 | Rec:  99.81 || Ex/s: 183.95\n",
      "\n",
      "===>  EVAL Epoch 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0% [██████████████████████████████] 100% | ETA: 00:00:00\n",
      "Total time elapsed: 00:03:17\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Epoch 1 || Run Time:   18.7 | Load Time:  179.2 || F1:  99.25 | Prec:  98.52 | Rec:  99.99 || Ex/s: 209.76\n",
      "\n",
      "* Best F1: tensor(99.2504, device='cuda:0')\n",
      "Saving best model...\n",
      "Done.\n",
      "---------------------\n",
      "\n",
      "===>  TRAIN Epoch 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0% [██████████████████████████████] 100% | ETA: 00:00:00\n",
      "Total time elapsed: 00:11:24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Epoch 2 || Run Time:  122.7 | Load Time:  564.5 || F1:  99.25 | Prec:  98.54 | Rec:  99.97 || Ex/s: 181.27\n",
      "\n",
      "===>  EVAL Epoch 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0% [██████████████████████████████] 100% | ETA: 00:00:00\n",
      "Total time elapsed: 00:03:20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Epoch 2 || Run Time:   19.0 | Load Time:  181.5 || F1:  99.27 | Prec:  98.56 | Rec:  99.99 || Ex/s: 207.10\n",
      "\n",
      "* Best F1: tensor(99.2714, device='cuda:0')\n",
      "Saving best model...\n",
      "Done.\n",
      "---------------------\n",
      "\n",
      "===>  TRAIN Epoch 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0% [██████████████████████████████] 100% | ETA: 00:00:00\n",
      "Total time elapsed: 00:11:21\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Epoch 3 || Run Time:  121.8 | Load Time:  562.6 || F1:  99.26 | Prec:  98.55 | Rec:  99.98 || Ex/s: 182.00\n",
      "\n",
      "===>  EVAL Epoch 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0% [██████████████████████████████] 100% | ETA: 00:00:00\n",
      "Total time elapsed: 00:03:17\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Epoch 3 || Run Time:   18.7 | Load Time:  178.9 || F1:  99.27 | Prec:  98.55 | Rec:  99.99 || Ex/s: 210.17\n",
      "\n",
      "---------------------\n",
      "\n",
      "===>  TRAIN Epoch 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0% [██████████████████████████████] 100% | ETA: 00:00:00\n",
      "Total time elapsed: 00:11:16\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Epoch 4 || Run Time:  120.5 | Load Time:  558.7 || F1:  99.26 | Prec:  98.55 | Rec:  99.97 || Ex/s: 183.41\n",
      "\n",
      "===>  EVAL Epoch 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0% [██████████████████████████████] 100% | ETA: 00:00:00\n",
      "Total time elapsed: 00:03:18\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Epoch 4 || Run Time:   18.8 | Load Time:  180.1 || F1:  99.27 | Prec:  98.56 | Rec:  99.99 || Ex/s: 208.76\n",
      "\n",
      "---------------------\n",
      "\n",
      "===>  TRAIN Epoch 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0% [██████████████████████████████] 100% | ETA: 00:00:00\n",
      "Total time elapsed: 00:11:21\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Epoch 5 || Run Time:  122.1 | Load Time:  562.5 || F1:  99.27 | Prec:  98.57 | Rec:  99.98 || Ex/s: 181.94\n",
      "\n",
      "===>  EVAL Epoch 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0% [██████████████████████████████] 100% | ETA: 00:00:00\n",
      "Total time elapsed: 00:03:18\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Epoch 5 || Run Time:   18.9 | Load Time:  179.7 || F1:  99.27 | Prec:  98.58 | Rec:  99.98 || Ex/s: 209.05\n",
      "\n",
      "* Best F1: tensor(99.2732, device='cuda:0')\n",
      "Saving best model...\n",
      "Done.\n",
      "---------------------\n",
      "\n",
      "===>  TRAIN Epoch 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0% [██████████████████████████████] 100% | ETA: 00:00:00\n",
      "Total time elapsed: 00:11:24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Epoch 6 || Run Time:  124.1 | Load Time:  563.4 || F1:  99.28 | Prec:  98.59 | Rec:  99.97 || Ex/s: 181.18\n",
      "\n",
      "===>  EVAL Epoch 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0% [██████████████████████████████] 100% | ETA: 00:00:00\n",
      "Total time elapsed: 00:03:19\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Epoch 6 || Run Time:   19.1 | Load Time:  180.0 || F1:  99.28 | Prec:  98.59 | Rec:  99.97 || Ex/s: 208.61\n",
      "\n",
      "* Best F1: tensor(99.2789, device='cuda:0')\n",
      "Saving best model...\n",
      "Done.\n",
      "---------------------\n",
      "\n",
      "===>  TRAIN Epoch 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0% [██████████████████████████████] 100% | ETA: 00:00:00\n",
      "Total time elapsed: 00:11:22\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Epoch 7 || Run Time:  123.4 | Load Time:  561.6 || F1:  99.30 | Prec:  98.65 | Rec:  99.96 || Ex/s: 181.84\n",
      "\n",
      "===>  EVAL Epoch 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0% [██████████████████████████████] 100% | ETA: 00:00:00\n",
      "Total time elapsed: 00:03:18\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Epoch 7 || Run Time:   19.0 | Load Time:  179.7 || F1:  99.29 | Prec:  98.63 | Rec:  99.96 || Ex/s: 208.91\n",
      "\n",
      "* Best F1: tensor(99.2902, device='cuda:0')\n",
      "Saving best model...\n",
      "Done.\n",
      "---------------------\n",
      "\n",
      "===>  TRAIN Epoch 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0% [██████████████████████████████] 100% | ETA: 00:00:00\n",
      "Total time elapsed: 00:11:21\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Epoch 8 || Run Time:  123.4 | Load Time:  561.4 || F1:  99.33 | Prec:  98.72 | Rec:  99.94 || Ex/s: 181.90\n",
      "\n",
      "===>  EVAL Epoch 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0% [██████████████████████████████] 100% | ETA: 00:00:00\n",
      "Total time elapsed: 00:03:18\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Epoch 8 || Run Time:   19.0 | Load Time:  179.6 || F1:  99.29 | Prec:  98.66 | Rec:  99.93 || Ex/s: 209.01\n",
      "\n",
      "* Best F1: tensor(99.2919, device='cuda:0')\n",
      "Saving best model...\n",
      "Done.\n",
      "---------------------\n",
      "\n",
      "===>  TRAIN Epoch 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0% [██████████████████████████████] 100% | ETA: 00:00:00\n",
      "Total time elapsed: 00:11:11\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Epoch 9 || Run Time:  119.9 | Load Time:  554.8 || F1:  99.35 | Prec:  98.77 | Rec:  99.94 || Ex/s: 184.65\n",
      "\n",
      "===>  EVAL Epoch 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0% [██████████████████████████████] 100% | ETA: 00:00:00\n",
      "Total time elapsed: 00:03:16\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Epoch 9 || Run Time:   18.5 | Load Time:  177.8 || F1:  99.29 | Prec:  98.69 | Rec:  99.90 || Ex/s: 211.53\n",
      "\n",
      "---------------------\n",
      "\n",
      "===>  TRAIN Epoch 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0% [██████████████████████████████] 100% | ETA: 00:00:00\n",
      "Total time elapsed: 00:11:07\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Epoch 10 || Run Time:  118.4 | Load Time:  551.7 || F1:  99.38 | Prec:  98.84 | Rec:  99.94 || Ex/s: 185.90\n",
      "\n",
      "===>  EVAL Epoch 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0% [██████████████████████████████] 100% | ETA: 00:00:00\n",
      "Total time elapsed: 00:03:14\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Epoch 10 || Run Time:   18.2 | Load Time:  176.4 || F1:  99.32 | Prec:  98.74 | Rec:  99.90 || Ex/s: 213.33\n",
      "\n",
      "* Best F1: tensor(99.3185, device='cuda:0')\n",
      "Saving best model...\n",
      "Done.\n",
      "---------------------\n",
      "\n",
      "Loading best model...\n",
      "Training done.\n",
      "===>  EVAL Epoch 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0% [██████████████████████████████] 100% | ETA: 00:00:00\n",
      "Total time elapsed: 00:03:31\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Epoch 10 || Run Time:   69.1 | Load Time:  143.3 || F1:  99.32 | Prec:  98.68 | Rec:  99.97 || Ex/s: 195.51\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(99.3170, device='cuda:0')"
      ]
     },
     "execution_count": 27,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a sifDiff model.\n",
    "model_rnn = dm.MatchingModel(attr_summarizer='rnn')\n",
    "model_rnn.initialize(train)  # Initilization\n",
    "\n",
    "# Train ing model on 15 epochs, batch size of 16, positive-to-negative \n",
    "# ratio to be 1:1. We save the best model (with the \n",
    "# highest F1 score on the validation set) to 'sifDiff_model.pth'.\n",
    "startTime = time.time()\n",
    "model_rnn.run_train(\n",
    "    train,\n",
    "    validation,\n",
    "    epochs=10,\n",
    "    batch_size=128,\n",
    "    best_save_path='rnn_model.pth',\n",
    "    pos_neg_ratio=2)\n",
    "executionTime_rnn = (time.time() - startTime)/60\n",
    "\n",
    "# Evaluate the accuracy on the test data.\n",
    "model_rnn.run_eval(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gc179yxv7imF",
    "outputId": "54f7e64f-5393-42ab-a872-ac6e1d1a34f3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===>  PREDICT Epoch 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0% [██████████████████████████████] 100% | ETA: 00:00:00\n",
      "Total time elapsed: 00:03:34\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Epoch 10 || Run Time:   71.3 | Load Time:  143.2 || F1:  99.32 | Prec:  98.68 | Rec:  99.97 || Ex/s: 193.58\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Load the model.\n",
    "model_rnn = dm.MatchingModel(attr_summarizer='rnn')\n",
    "model_rnn.load_state('rnn_model.pth')\n",
    "# Load the candidate set. Note that the trained model is an input parameter as we need to trained \n",
    "# model for candidate set preprocessing.\n",
    "predictions_rnn = model_rnn.run_prediction(test, output_attributes=list(test.get_raw_table().columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Kp6gm50b7k1Z"
   },
   "outputs": [],
   "source": [
    "# get training data set and compute performance scores\n",
    "score_rnn = scores(executionTime_rnn, predictions_rnn, 0, train_n.shape[0], model = 'rnn')\n",
    "prec_matrix = prec_matrix.append(score_rnn, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "94MZxpnE7mEF"
   },
   "outputs": [],
   "source": [
    "high_score_pairs = predictions_rnn[predictions_rnn['match_score'] >= 0.9].sort_values(by=['match_score'], ascending=False)\n",
    "predictions_rnn['match_prediction'] = predictions_rnn['match_score'].apply(lambda score: 1 if score >= 0.5 else 0)\n",
    "# Reorder columns to avoid scrolling...\n",
    "predictions_rnn =  predictions_rnn[['match_score', 'match_prediction'] + predictions_rnn.columns.values[1:-1].tolist()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "Cf-nJNzhKTYP"
   },
   "outputs": [],
   "source": [
    "path_predictions = os.path.join('.', 'Dissertation_Data_2', 'predictions_rnn.csv')\n",
    "predictions_rnn.to_csv(path_predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iw5C1KvJ741V"
   },
   "source": [
    "### Attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AGeH4jlJ8akJ",
    "outputId": "b809d56d-819d-44a5-bc7e-1038e5228b37"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py:974: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
      "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n",
      "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py:949: UserWarning: Using non-full backward hooks on a Module that does not take as input a single Tensor or a tuple of Tensors is deprecated and will be removed in future versions. This hook will be missing some of the grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
      "  warnings.warn(\"Using non-full backward hooks on a Module that does not take as input a \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Number of trainable parameters: 15069302\n",
      "===>  TRAIN Epoch 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py:939: UserWarning: Using non-full backward hooks on a Module that does not return a single Tensor or a tuple of Tensors is deprecated and will be removed in future versions. This hook will be missing some of the grad_output. Please use register_full_backward_hook to get the documented behavior.\n",
      "  warnings.warn(\"Using non-full backward hooks on a Module that does not return a \"\n",
      "/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2742: UserWarning: reduction: 'mean' divides the total loss by both the batch size and the support size.'batchmean' divides only by the batch size, and aligns with the KL div math definition.'mean' will be changed to behave the same as 'batchmean' in the next major release.\n",
      "  \"reduction: 'mean' divides the total loss by both the batch size and the support size.\"\n",
      "0% [██████████████████████████████] 100% | ETA: 00:00:00\n",
      "Total time elapsed: 00:13:15\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Epoch 1 || Run Time:  253.0 | Load Time:  545.6 || F1:  98.05 | Prec:  96.49 | Rec:  99.66 || Ex/s: 155.97\n",
      "\n",
      "===>  EVAL Epoch 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0% [██████████████████████████████] 100% | ETA: 00:00:00\n",
      "Total time elapsed: 00:03:51\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Epoch 1 || Run Time:   50.9 | Load Time:  180.8 || F1:  99.20 | Prec:  98.48 | Rec:  99.93 || Ex/s: 179.20\n",
      "\n",
      "* Best F1: tensor(99.2042, device='cuda:0')\n",
      "Saving best model...\n",
      "Done.\n",
      "---------------------\n",
      "\n",
      "===>  TRAIN Epoch 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0% [██████████████████████████████] 100% | ETA: 00:00:00\n",
      "Total time elapsed: 00:13:33\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Epoch 2 || Run Time:  262.6 | Load Time:  554.1 || F1:  99.23 | Prec:  98.54 | Rec:  99.94 || Ex/s: 152.52\n",
      "\n",
      "===>  EVAL Epoch 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0% [██████████████████████████████] 100% | ETA: 00:00:00\n",
      "Total time elapsed: 00:03:47\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Epoch 2 || Run Time:   49.2 | Load Time:  178.8 || F1:  99.27 | Prec:  98.61 | Rec:  99.95 || Ex/s: 182.12\n",
      "\n",
      "* Best F1: tensor(99.2711, device='cuda:0')\n",
      "Saving best model...\n",
      "Done.\n",
      "---------------------\n",
      "\n",
      "===>  TRAIN Epoch 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0% [██████████████████████████████] 100% | ETA: 00:00:00\n",
      "Total time elapsed: 00:13:35\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Epoch 3 || Run Time:  262.1 | Load Time:  556.4 || F1:  99.26 | Prec:  98.58 | Rec:  99.96 || Ex/s: 152.17\n",
      "\n",
      "===>  EVAL Epoch 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0% [██████████████████████████████] 100% | ETA: 00:00:00\n",
      "Total time elapsed: 00:03:51\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Epoch 3 || Run Time:   50.7 | Load Time:  181.2 || F1:  99.28 | Prec:  98.67 | Rec:  99.90 || Ex/s: 179.01\n",
      "\n",
      "* Best F1: tensor(99.2803, device='cuda:0')\n",
      "Saving best model...\n",
      "Done.\n",
      "---------------------\n",
      "\n",
      "===>  TRAIN Epoch 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0% [██████████████████████████████] 100% | ETA: 00:00:00\n",
      "Total time elapsed: 00:13:43\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Epoch 4 || Run Time:  267.3 | Load Time:  559.7 || F1:  99.29 | Prec:  98.62 | Rec:  99.96 || Ex/s: 150.63\n",
      "\n",
      "===>  EVAL Epoch 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0% [██████████████████████████████] 100% | ETA: 00:00:00\n",
      "Total time elapsed: 00:03:50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Epoch 4 || Run Time:   50.1 | Load Time:  180.7 || F1:  99.29 | Prec:  98.68 | Rec:  99.90 || Ex/s: 179.85\n",
      "\n",
      "* Best F1: tensor(99.2899, device='cuda:0')\n",
      "Saving best model...\n",
      "Done.\n",
      "---------------------\n",
      "\n",
      "===>  TRAIN Epoch 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0% [██████████████████████████████] 100% | ETA: 00:00:00\n",
      "Total time elapsed: 00:13:28\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Epoch 5 || Run Time:  258.3 | Load Time:  553.9 || F1:  99.30 | Prec:  98.66 | Rec:  99.95 || Ex/s: 153.36\n",
      "\n",
      "===>  EVAL Epoch 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0% [██████████████████████████████] 100% | ETA: 00:00:00\n",
      "Total time elapsed: 00:03:50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Epoch 5 || Run Time:   49.9 | Load Time:  180.7 || F1:  99.28 | Prec:  98.68 | Rec:  99.90 || Ex/s: 180.09\n",
      "\n",
      "---------------------\n",
      "\n",
      "===>  TRAIN Epoch 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0% [██████████████████████████████] 100% | ETA: 00:00:00\n",
      "Total time elapsed: 00:13:23\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Epoch 6 || Run Time:  255.6 | Load Time:  550.9 || F1:  99.33 | Prec:  98.72 | Rec:  99.95 || Ex/s: 154.45\n",
      "\n",
      "===>  EVAL Epoch 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0% [██████████████████████████████] 100% | ETA: 00:00:00\n",
      "Total time elapsed: 00:03:47\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Epoch 6 || Run Time:   48.7 | Load Time:  178.6 || F1:  99.30 | Prec:  98.70 | Rec:  99.90 || Ex/s: 182.65\n",
      "\n",
      "* Best F1: tensor(99.2956, device='cuda:0')\n",
      "Saving best model...\n",
      "Done.\n",
      "---------------------\n",
      "\n",
      "===>  TRAIN Epoch 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0% [██████████████████████████████] 100% | ETA: 00:00:00\n",
      "Total time elapsed: 00:13:30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Epoch 7 || Run Time:  259.9 | Load Time:  553.9 || F1:  99.36 | Prec:  98.78 | Rec:  99.94 || Ex/s: 153.06\n",
      "\n",
      "===>  EVAL Epoch 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0% [██████████████████████████████] 100% | ETA: 00:00:00\n",
      "Total time elapsed: 00:03:50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Epoch 7 || Run Time:   50.1 | Load Time:  180.5 || F1:  99.30 | Prec:  98.71 | Rec:  99.89 || Ex/s: 180.11\n",
      "\n",
      "---------------------\n",
      "\n",
      "===>  TRAIN Epoch 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0% [██████████████████████████████] 100% | ETA: 00:00:00\n",
      "Total time elapsed: 00:13:15\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Epoch 8 || Run Time:  251.6 | Load Time:  547.6 || F1:  99.39 | Prec:  98.82 | Rec:  99.95 || Ex/s: 155.87\n",
      "\n",
      "===>  EVAL Epoch 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0% [██████████████████████████████] 100% | ETA: 00:00:00\n",
      "Total time elapsed: 00:03:44\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Epoch 8 || Run Time:   47.6 | Load Time:  176.6 || F1:  99.29 | Prec:  98.73 | Rec:  99.86 || Ex/s: 185.23\n",
      "\n",
      "---------------------\n",
      "\n",
      "===>  TRAIN Epoch 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0% [██████████████████████████████] 100% | ETA: 00:00:00\n",
      "Total time elapsed: 00:13:14\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Epoch 9 || Run Time:  251.3 | Load Time:  546.5 || F1:  99.39 | Prec:  98.85 | Rec:  99.94 || Ex/s: 156.13\n",
      "\n",
      "===>  EVAL Epoch 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0% [██████████████████████████████] 100% | ETA: 00:00:00\n",
      "Total time elapsed: 00:03:43\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Epoch 9 || Run Time:   47.4 | Load Time:  176.0 || F1:  99.29 | Prec:  98.74 | Rec:  99.85 || Ex/s: 185.86\n",
      "\n",
      "---------------------\n",
      "\n",
      "===>  TRAIN Epoch 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0% [██████████████████████████████] 100% | ETA: 00:00:00\n",
      "Total time elapsed: 00:13:10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Epoch 10 || Run Time:  248.7 | Load Time:  545.7 || F1:  99.41 | Prec:  98.88 | Rec:  99.95 || Ex/s: 156.81\n",
      "\n",
      "===>  EVAL Epoch 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0% [██████████████████████████████] 100% | ETA: 00:00:00\n",
      "Total time elapsed: 00:03:46\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Epoch 10 || Run Time:   48.3 | Load Time:  178.6 || F1:  99.31 | Prec:  98.77 | Rec:  99.85 || Ex/s: 183.01\n",
      "\n",
      "* Best F1: tensor(99.3067, device='cuda:0')\n",
      "Saving best model...\n",
      "Done.\n",
      "---------------------\n",
      "\n",
      "Loading best model...\n",
      "Training done.\n",
      "===>  EVAL Epoch 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0% [██████████████████████████████] 100% | ETA: 00:00:00\n",
      "Total time elapsed: 00:05:32\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Epoch 10 || Run Time:  188.4 | Load Time:  145.1 || F1:  99.28 | Prec:  98.70 | Rec:  99.86 || Ex/s: 124.50\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(99.2761, device='cuda:0')"
      ]
     },
     "execution_count": 32,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a sifDiff model.\n",
    "model_attention = dm.MatchingModel(attr_summarizer='attention')\n",
    "model_attention.initialize(train)  # Initilization\n",
    "\n",
    "# Train ing model on 15 epochs, batch size of 16, positive-to-negative \n",
    "# ratio to be 1:1. We save the best model (with the \n",
    "# highest F1 score on the validation set) to 'sifDiff_model.pth'.\n",
    "startTime = time.time()\n",
    "model_attention.run_train(\n",
    "    train,\n",
    "    validation,\n",
    "    epochs=10,\n",
    "    batch_size=128,\n",
    "    best_save_path='attention_model.pth',\n",
    "    pos_neg_ratio=2)\n",
    "executionTime_attention = (time.time() - startTime)/60\n",
    "\n",
    "# Evaluate the accuracy on the test data.\n",
    "model_attention.run_eval(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "t_7ZOqPN8bRQ",
    "outputId": "038459c5-a176-456d-e216-7ff36ab4ea3e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===>  PREDICT Epoch 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0% [██████████████████████████████] 100% | ETA: 00:00:00\n",
      "Total time elapsed: 00:05:31\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Epoch 10 || Run Time:  188.4 | Load Time:  144.1 || F1:  99.28 | Prec:  98.70 | Rec:  99.86 || Ex/s: 124.90\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Load the model.\n",
    "model_attention = dm.MatchingModel(attr_summarizer='attention')\n",
    "model_attention.load_state('attention_model.pth')\n",
    "# Load the candidate set. Note that the trained model is an input parameter as we need to trained \n",
    "# model for candidate set preprocessing.\n",
    "predictions_attention = model_attention.run_prediction(test, output_attributes=list(test.get_raw_table().columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "id": "c9Oinh9d8dXG"
   },
   "outputs": [],
   "source": [
    "# get training data set and compute performance scores\n",
    "score_attention = scores(executionTime_attention, predictions_attention, 0, train_n.shape[0], model = 'attention')\n",
    "prec_matrix = prec_matrix.append(score_attention, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "id": "ZkXEKbjq8et0"
   },
   "outputs": [],
   "source": [
    "high_score_pairs = predictions_attention[predictions_attention['match_score'] >= 0.9].sort_values(by=['match_score'], ascending=False)\n",
    "predictions_attention['match_prediction'] = predictions_attention['match_score'].apply(lambda score: 1 if score >= 0.5 else 0)\n",
    "# Reorder columns to avoid scrolling...\n",
    "predictions_attention =  predictions_attention[['match_score', 'match_prediction'] + predictions_attention.columns.values[1:-1].tolist()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "id": "8wsSVHGaKYuR"
   },
   "outputs": [],
   "source": [
    "path_predictions = os.path.join('.', 'Dissertation_Data_2', 'predictions_att.csv')\n",
    "predictions_attention.to_csv(path_predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "N4WFMmtd68Ut"
   },
   "source": [
    "### Hybrid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xlQNZScvCOD5",
    "outputId": "ff63eae6-c994-4aba-bc3a-85f8ff7ef803"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py:949: UserWarning: Using non-full backward hooks on a Module that does not take as input a single Tensor or a tuple of Tensors is deprecated and will be removed in future versions. This hook will be missing some of the grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
      "  warnings.warn(\"Using non-full backward hooks on a Module that does not take as input a \"\n",
      "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py:974: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
      "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Number of trainable parameters: 33136817\n",
      "===>  TRAIN Epoch 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py:939: UserWarning: Using non-full backward hooks on a Module that does not return a single Tensor or a tuple of Tensors is deprecated and will be removed in future versions. This hook will be missing some of the grad_output. Please use register_full_backward_hook to get the documented behavior.\n",
      "  warnings.warn(\"Using non-full backward hooks on a Module that does not return a \"\n",
      "/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2742: UserWarning: reduction: 'mean' divides the total loss by both the batch size and the support size.'batchmean' divides only by the batch size, and aligns with the KL div math definition.'mean' will be changed to behave the same as 'batchmean' in the next major release.\n",
      "  \"reduction: 'mean' divides the total loss by both the batch size and the support size.\"\n",
      "0% [██████████████████████████████] 100% | ETA: 00:00:00\n",
      "Total time elapsed: 00:16:34\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Epoch 1 || Run Time:  454.0 | Load Time:  544.6 || F1:  98.51 | Prec:  97.20 | Rec:  99.85 || Ex/s: 124.74\n",
      "\n",
      "===>  EVAL Epoch 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0% [██████████████████████████████] 100% | ETA: 00:00:00\n",
      "Total time elapsed: 00:04:15\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Epoch 1 || Run Time:   76.9 | Load Time:  178.7 || F1:  99.23 | Prec:  98.48 | Rec:  99.98 || Ex/s: 162.45\n",
      "\n",
      "* Best F1: tensor(99.2275, device='cuda:0')\n",
      "Saving best model...\n",
      "Done.\n",
      "---------------------\n",
      "\n",
      "===>  TRAIN Epoch 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0% [██████████████████████████████] 100% | ETA: 00:00:00\n",
      "Total time elapsed: 00:16:43\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Epoch 2 || Run Time:  459.2 | Load Time:  549.1 || F1:  99.24 | Prec:  98.54 | Rec:  99.94 || Ex/s: 123.54\n",
      "\n",
      "===>  EVAL Epoch 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0% [██████████████████████████████] 100% | ETA: 00:00:00\n",
      "Total time elapsed: 00:04:18\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Epoch 2 || Run Time:   79.4 | Load Time:  178.9 || F1:  99.28 | Prec:  98.59 | Rec:  99.97 || Ex/s: 160.73\n",
      "\n",
      "* Best F1: tensor(99.2770, device='cuda:0')\n",
      "Saving best model...\n",
      "Done.\n",
      "---------------------\n",
      "\n",
      "===>  TRAIN Epoch 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0% [██████████████████████████████] 100% | ETA: 00:00:00\n",
      "Total time elapsed: 00:16:42\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Epoch 3 || Run Time:  458.7 | Load Time:  548.4 || F1:  99.27 | Prec:  98.61 | Rec:  99.95 || Ex/s: 123.69\n",
      "\n",
      "===>  EVAL Epoch 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0% [██████████████████████████████] 100% | ETA: 00:00:00\n",
      "Total time elapsed: 00:04:14\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Epoch 3 || Run Time:   76.4 | Load Time:  178.2 || F1:  99.29 | Prec:  98.71 | Rec:  99.88 || Ex/s: 163.11\n",
      "\n",
      "* Best F1: tensor(99.2916, device='cuda:0')\n",
      "Saving best model...\n",
      "Done.\n",
      "---------------------\n",
      "\n",
      "===>  TRAIN Epoch 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0% [██████████████████████████████] 100% | ETA: 00:00:00\n",
      "Total time elapsed: 00:16:48\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Epoch 4 || Run Time:  463.3 | Load Time:  550.0 || F1:  99.30 | Prec:  98.67 | Rec:  99.94 || Ex/s: 122.93\n",
      "\n",
      "===>  EVAL Epoch 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0% [██████████████████████████████] 100% | ETA: 00:00:00\n",
      "Total time elapsed: 00:04:16\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Epoch 4 || Run Time:   77.5 | Load Time:  179.1 || F1:  99.30 | Prec:  98.71 | Rec:  99.90 || Ex/s: 161.87\n",
      "\n",
      "* Best F1: tensor(99.3013, device='cuda:0')\n",
      "Saving best model...\n",
      "Done.\n",
      "---------------------\n",
      "\n",
      "===>  TRAIN Epoch 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0% [██████████████████████████████] 100% | ETA: 00:00:00\n",
      "Total time elapsed: 00:16:49\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Epoch 5 || Run Time:  463.9 | Load Time:  549.8 || F1:  99.34 | Prec:  98.75 | Rec:  99.93 || Ex/s: 122.88\n",
      "\n",
      "===>  EVAL Epoch 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0% [██████████████████████████████] 100% | ETA: 00:00:00\n",
      "Total time elapsed: 00:04:15\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Epoch 5 || Run Time:   76.9 | Load Time:  178.6 || F1:  99.30 | Prec:  98.80 | Rec:  99.80 || Ex/s: 162.50\n",
      "\n",
      "---------------------\n",
      "\n",
      "===>  TRAIN Epoch 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0% [██████████████████████████████] 100% | ETA: 00:00:00\n",
      "Total time elapsed: 00:16:30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Epoch 6 || Run Time:  452.6 | Load Time:  542.3 || F1:  99.37 | Prec:  98.83 | Rec:  99.91 || Ex/s: 125.20\n",
      "\n",
      "===>  EVAL Epoch 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0% [██████████████████████████████] 100% | ETA: 00:00:00\n",
      "Total time elapsed: 00:04:09\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Epoch 6 || Run Time:   74.3 | Load Time:  175.5 || F1:  99.30 | Prec:  98.73 | Rec:  99.87 || Ex/s: 166.24\n",
      "\n",
      "---------------------\n",
      "\n",
      "===>  TRAIN Epoch 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0% [██████████████████████████████] 100% | ETA: 00:00:00\n",
      "Total time elapsed: 00:16:24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Epoch 7 || Run Time:  448.7 | Load Time:  540.5 || F1:  99.40 | Prec:  98.91 | Rec:  99.90 || Ex/s: 125.92\n",
      "\n",
      "===>  EVAL Epoch 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0% [██████████████████████████████] 100% | ETA: 00:00:00\n",
      "Total time elapsed: 00:04:12\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Epoch 7 || Run Time:   76.8 | Load Time:  175.8 || F1:  99.30 | Prec:  98.74 | Rec:  99.86 || Ex/s: 164.38\n",
      "\n",
      "---------------------\n",
      "\n",
      "===>  TRAIN Epoch 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0% [██████████████████████████████] 100% | ETA: 00:00:00\n",
      "Total time elapsed: 00:16:27\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Epoch 8 || Run Time:  450.6 | Load Time:  541.3 || F1:  99.43 | Prec:  98.97 | Rec:  99.91 || Ex/s: 125.58\n",
      "\n",
      "===>  EVAL Epoch 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0% [██████████████████████████████] 100% | ETA: 00:00:00\n",
      "Total time elapsed: 00:04:11\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Epoch 8 || Run Time:   75.1 | Load Time:  176.0 || F1:  99.31 | Prec:  98.76 | Rec:  99.87 || Ex/s: 165.35\n",
      "\n",
      "* Best F1: tensor(99.3145, device='cuda:0')\n",
      "Saving best model...\n",
      "Done.\n",
      "---------------------\n",
      "\n",
      "===>  TRAIN Epoch 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0% [██████████████████████████████] 100% | ETA: 00:00:00\n",
      "Total time elapsed: 00:16:27\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Epoch 9 || Run Time:  451.4 | Load Time:  540.8 || F1:  99.47 | Prec:  99.02 | Rec:  99.92 || Ex/s: 125.54\n",
      "\n",
      "===>  EVAL Epoch 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0% [██████████████████████████████] 100% | ETA: 00:00:00\n",
      "Total time elapsed: 00:04:11\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Epoch 9 || Run Time:   75.2 | Load Time:  176.2 || F1:  99.31 | Prec:  98.79 | Rec:  99.84 || Ex/s: 165.21\n",
      "\n",
      "---------------------\n",
      "\n",
      "===>  TRAIN Epoch 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0% [██████████████████████████████] 100% | ETA: 00:00:00\n",
      "Total time elapsed: 00:16:17\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Epoch 10 || Run Time:  445.4 | Load Time:  536.4 || F1:  99.49 | Prec:  99.07 | Rec:  99.92 || Ex/s: 126.87\n",
      "\n",
      "===>  EVAL Epoch 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0% [██████████████████████████████] 100% | ETA: 00:00:00\n",
      "Total time elapsed: 00:04:07\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Epoch 10 || Run Time:   73.5 | Load Time:  174.2 || F1:  99.31 | Prec:  98.82 | Rec:  99.82 || Ex/s: 167.68\n",
      "\n",
      "---------------------\n",
      "\n",
      "Loading best model...\n",
      "Training done.\n",
      "===>  EVAL Epoch 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0% [██████████████████████████████] 100% | ETA: 00:00:00\n",
      "Total time elapsed: 00:07:03\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Epoch 8 || Run Time:  282.5 | Load Time:  141.8 || F1:  99.27 | Prec:  98.67 | Rec:  99.89 || Ex/s:  97.86\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(99.2744, device='cuda:0')"
      ]
     },
     "execution_count": 37,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a sifDiff model.\n",
    "model_hyb = dm.MatchingModel(attr_summarizer='hybrid')\n",
    "model_hyb.initialize(train)  # Initilization\n",
    "\n",
    "# Train ing model on 15 epochs, batch size of 16, positive-to-negative \n",
    "# ratio to be 1:1. We save the best model (with the \n",
    "# highest F1 score on the validation set) to 'sifDiff_model.pth'.\n",
    "startTime = time.time()\n",
    "model_hyb.run_train(\n",
    "    train,\n",
    "    validation,\n",
    "    epochs=10,\n",
    "    batch_size=128,\n",
    "    best_save_path='hybrid_model.pth',\n",
    "    pos_neg_ratio=2)\n",
    "executionTime_hyb = (time.time() - startTime)/60\n",
    "\n",
    "# Evaluate the accuracy on the test data.\n",
    "model_hyb.run_eval(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lg1SIDZ1CRH1",
    "outputId": "b4e44c9b-c94b-4a33-c3aa-09b767e6a82a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===>  PREDICT Epoch 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0% [██████████████████████████████] 100% | ETA: 00:00:00\n",
      "Total time elapsed: 00:07:05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Epoch 8 || Run Time:  285.5 | Load Time:  141.4 || F1:  99.27 | Prec:  98.67 | Rec:  99.89 || Ex/s:  97.27\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Load the model.\n",
    "model_hyb = dm.MatchingModel(attr_summarizer='hybrid')\n",
    "model_hyb.load_state('hybrid_model.pth')\n",
    "# Load the candidate set. Note that the trained model is an input parameter as we need to trained \n",
    "# model for candidate set preprocessing.\n",
    "predictions_hyb = model_hyb.run_prediction(test, output_attributes=list(test.get_raw_table().columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "id": "tjX-7VOjuDth"
   },
   "outputs": [],
   "source": [
    "# get training data set and compute performance scores\n",
    "score_hyb = scores(executionTime_hyb, predictions_hyb, 0, train_n.shape[0], model = 'hybrid')\n",
    "prec_matrix =prec_matrix.append(score_hyb, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "id": "lcRMsCgx8uql"
   },
   "outputs": [],
   "source": [
    "high_score_pairs = predictions_hyb[predictions_hyb['match_score'] >= 0.9].sort_values(by=['match_score'], ascending=False)\n",
    "predictions_hyb['match_prediction'] = predictions_hyb['match_score'].apply(lambda score: 1 if score >= 0.5 else 0)\n",
    "# Reorder columns to avoid scrolling...\n",
    "predictions_hyb =  predictions_hyb[['match_score', 'match_prediction'] + predictions_hyb.columns.values[1:-1].tolist()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "id": "VH5r-mSY8yq2"
   },
   "outputs": [],
   "source": [
    "path_DL_res = os.path.join('.', 'Dissertation_Data_2', 'DL_res.csv')\n",
    "prec_matrix.to_csv(path_DL_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "id": "trHPJAY-KbXF"
   },
   "outputs": [],
   "source": [
    "path_predictions = os.path.join('.', 'Dissertation_Data_2', 'predictions_hyb.csv')\n",
    "predictions_hyb.to_csv(path_predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7d0yw7KbPLUk"
   },
   "source": [
    "## ML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8-j6XFnb1-OF",
    "outputId": "a754e8d2-73a9-4d80-d492-6f6ee5791b10"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:py_entitymatching.io.parsers:Metadata file is not present in the given path; proceeding to read the csv file.\n"
     ]
    }
   ],
   "source": [
    "Cora.to_csv(os.path.join('.', 'Dissertation_Data_2', 'cora.csv'),index=False)\n",
    "Cora = em.read_csv_metadata(os.path.join('.', 'Dissertation_Data_2', 'cora.csv'), key='id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "id": "Js7yJS2zAH9Z"
   },
   "outputs": [],
   "source": [
    "path_cand = os.path.join('.', 'Dissertation_Data_2', 'cand.csv')\n",
    "cand.to_csv(path_cand,index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "S98srxKyPNNp",
    "outputId": "5dc160e2-07b7-4c2d-b19d-1334fda26f61"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:py_entitymatching.io.parsers:Metadata file is not present in the given path; proceeding to read the csv file.\n",
      "/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py:3361: DtypeWarning: Columns (7,9,13,15,17,18,20,21,22,23,24,25,27,28,30,31,32) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  if (await self.run_code(code, result,  async_=asy)):\n",
      "/usr/local/lib/python3.7/dist-packages/py_entitymatching/matcher/matcherutils.py:224: FutureWarning: The pandas.np module is deprecated and will be removed from pandas in a future version. Import numpy directly instead\n",
      "  imp.statistics_[pd.np.isnan(imp.statistics_)] = val_all_nans\n"
     ]
    }
   ],
   "source": [
    "# creating dataset for ML matching\n",
    "S = em.read_csv_metadata(path_cand, \n",
    "                         key='_id',\n",
    "                         ltable=Cora, rtable=Cora, \n",
    "                         fk_ltable='ltable_id', fk_rtable='rtable_id')\n",
    "\n",
    "# Split S into training and test data\n",
    "IJ = em.split_train_test(S, train_proportion=0.5, random_state=0)\n",
    "I = IJ['train']\n",
    "J = IJ['test']\n",
    "\n",
    "# Generate a set of features\n",
    "F = em.get_features_for_matching(Cora, Cora, validate_inferred_attr_types=False)\n",
    "\n",
    "# Convert the I into a set of feature vectors using F\n",
    "H = em.extract_feature_vecs(I, \n",
    "                            feature_table=F, \n",
    "                            attrs_after='label',\n",
    "                            show_progress=False)\n",
    "\n",
    "# Create a set of ML-matchers\n",
    "dt = em.DTMatcher(name='DecisionTree', random_state=0)\n",
    "svm = em.SVMMatcher(name='SVM', random_state=0)\n",
    "rf = em.RFMatcher(name='RF', random_state=0)\n",
    "lg = em.LogRegMatcher(name='LogReg', random_state=0)\n",
    "ln = em.LinRegMatcher(name='LinReg')\n",
    "\n",
    "# Impute feature vectors with the mean of the column values.\n",
    "H = em.impute_table(H, exclude_attrs=['_id', 'ltable_id', 'rtable_id', 'label'], missing_val = np.nan, strategy='mean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 263
    },
    "id": "h0t9SHpSQEZU",
    "outputId": "f5628733-86e1-4e6a-ae12-1ffb728b4d9b"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/joblib/externals/loky/process_executor.py:691: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  \"timeout or by a memory leak.\", UserWarning\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Matcher</th>\n",
       "      <th>Average precision</th>\n",
       "      <th>Average recall</th>\n",
       "      <th>Average f1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DecisionTree</td>\n",
       "      <td>0.998789</td>\n",
       "      <td>0.998665</td>\n",
       "      <td>0.998727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RF</td>\n",
       "      <td>0.999425</td>\n",
       "      <td>0.999301</td>\n",
       "      <td>0.999363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SVM</td>\n",
       "      <td>0.920802</td>\n",
       "      <td>0.973276</td>\n",
       "      <td>0.946311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LinReg</td>\n",
       "      <td>0.916783</td>\n",
       "      <td>0.977912</td>\n",
       "      <td>0.946357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LogReg</td>\n",
       "      <td>0.941104</td>\n",
       "      <td>0.957282</td>\n",
       "      <td>0.949109</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Matcher  Average precision  Average recall  Average f1\n",
       "0  DecisionTree           0.998789        0.998665    0.998727\n",
       "1            RF           0.999425        0.999301    0.999363\n",
       "2           SVM           0.920802        0.973276    0.946311\n",
       "3        LinReg           0.916783        0.977912    0.946357\n",
       "4        LogReg           0.941104        0.957282    0.949109"
      ]
     },
     "execution_count": 46,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Select the best ML matcher using CV\n",
    "result = em.select_matcher([dt, rf, svm, ln, lg], table=H, \n",
    "        exclude_attrs=['_id', 'ltable_id', 'rtable_id', 'label'],\n",
    "        k=10,\n",
    "        target_attr='label', metric_to_select_matcher='f1', random_state=0)\n",
    "result['cv_stats']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 330
    },
    "id": "_TcPtWyPQGeM",
    "outputId": "545364b3-df27-4fe9-83f1-7087741504a2"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Matcher</th>\n",
       "      <th>Num folds</th>\n",
       "      <th>Fold 1</th>\n",
       "      <th>Fold 2</th>\n",
       "      <th>Fold 3</th>\n",
       "      <th>Fold 4</th>\n",
       "      <th>Fold 5</th>\n",
       "      <th>Fold 6</th>\n",
       "      <th>Fold 7</th>\n",
       "      <th>Fold 8</th>\n",
       "      <th>Fold 9</th>\n",
       "      <th>Fold 10</th>\n",
       "      <th>Mean score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DecisionTree</td>\n",
       "      <td>&lt;py_entitymatching.matcher.dtmatcher.DTMatcher object at 0x7feb89be5bd0&gt;</td>\n",
       "      <td>10</td>\n",
       "      <td>0.998445</td>\n",
       "      <td>0.998915</td>\n",
       "      <td>0.998275</td>\n",
       "      <td>0.998744</td>\n",
       "      <td>0.998592</td>\n",
       "      <td>0.999370</td>\n",
       "      <td>0.998160</td>\n",
       "      <td>0.998923</td>\n",
       "      <td>0.999236</td>\n",
       "      <td>0.999225</td>\n",
       "      <td>0.998789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RF</td>\n",
       "      <td>&lt;py_entitymatching.matcher.rfmatcher.RFMatcher object at 0x7feb89be5fd0&gt;</td>\n",
       "      <td>10</td>\n",
       "      <td>0.999223</td>\n",
       "      <td>0.999380</td>\n",
       "      <td>0.999216</td>\n",
       "      <td>0.999529</td>\n",
       "      <td>0.999687</td>\n",
       "      <td>0.999371</td>\n",
       "      <td>0.999233</td>\n",
       "      <td>0.999538</td>\n",
       "      <td>0.999542</td>\n",
       "      <td>0.999535</td>\n",
       "      <td>0.999425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SVM</td>\n",
       "      <td>&lt;py_entitymatching.matcher.svmmatcher.SVMMatcher object at 0x7fed0cb613d0&gt;</td>\n",
       "      <td>10</td>\n",
       "      <td>0.923767</td>\n",
       "      <td>0.918326</td>\n",
       "      <td>0.919395</td>\n",
       "      <td>0.920059</td>\n",
       "      <td>0.918663</td>\n",
       "      <td>0.919345</td>\n",
       "      <td>0.923750</td>\n",
       "      <td>0.922360</td>\n",
       "      <td>0.923277</td>\n",
       "      <td>0.919073</td>\n",
       "      <td>0.920802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LinReg</td>\n",
       "      <td>&lt;py_entitymatching.matcher.linregmatcher.LinRegMatcher object at 0x7fed01ead810&gt;</td>\n",
       "      <td>10</td>\n",
       "      <td>0.922139</td>\n",
       "      <td>0.917235</td>\n",
       "      <td>0.914819</td>\n",
       "      <td>0.916728</td>\n",
       "      <td>0.914052</td>\n",
       "      <td>0.914353</td>\n",
       "      <td>0.916691</td>\n",
       "      <td>0.917208</td>\n",
       "      <td>0.921182</td>\n",
       "      <td>0.913421</td>\n",
       "      <td>0.916783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LogReg</td>\n",
       "      <td>&lt;py_entitymatching.matcher.logregmatcher.LogRegMatcher object at 0x7feb89be5e10&gt;</td>\n",
       "      <td>10</td>\n",
       "      <td>0.954116</td>\n",
       "      <td>0.937386</td>\n",
       "      <td>0.944051</td>\n",
       "      <td>0.939833</td>\n",
       "      <td>0.947106</td>\n",
       "      <td>0.927430</td>\n",
       "      <td>0.950272</td>\n",
       "      <td>0.942197</td>\n",
       "      <td>0.934694</td>\n",
       "      <td>0.933951</td>\n",
       "      <td>0.941104</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Name  ... Mean score\n",
       "0  DecisionTree  ...   0.998789\n",
       "1            RF  ...   0.999425\n",
       "2           SVM  ...   0.920802\n",
       "3        LinReg  ...   0.916783\n",
       "4        LogReg  ...   0.941104\n",
       "\n",
       "[5 rows x 14 columns]"
      ]
     },
     "execution_count": 47,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result['drill_down_cv_stats']['precision']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZO3awE9bfMje"
   },
   "outputs": [],
   "source": [
    "path_ML_res = os.path.join('.', 'Dissertation_Data_2', 'ML_res.csv')\n",
    "\n",
    "result['cv_stats'].to_csv(path_ML_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Now-1z-JAexY",
    "outputId": "24df2f7c-7e6b-4117-ab29-0d4e91e39ebf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "138031597\n"
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "try:\n",
    "  while True:\n",
    "    i += 1\n",
    "  if not i % 1000:\n",
    "    gc.collect()\n",
    "except KeyboardInterrupt:\n",
    " print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JXlbl-ArpNEE"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "Dissertation_Cora.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
