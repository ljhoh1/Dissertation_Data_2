{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wwXYItrumLni"
   },
   "source": [
    "# Material"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8rSNrFIHmOKp"
   },
   "source": [
    "## Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vgFTV4_-qJ2s",
    "outputId": "9ed9485b-00a0-4293-d8d2-0b8270c8c7d8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Verify pandas==1.2.4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/sklearn/externals/six.py:31: FutureWarning: The module is deprecated in version 0.21 and will be removed in version 0.23 since we've dropped support for Python 2.7. Please rely on the official version of six (https://pypi.org/project/six/).\n",
      "  \"(https://pypi.org/project/six/).\", FutureWarning)\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/utils/deprecation.py:144: FutureWarning: The sklearn.neighbors.base module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.neighbors. Anything that cannot be imported from sklearn.neighbors is now part of the private API.\n",
      "  warnings.warn(message, FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "# importing the necessary libraries\n",
    "import scipy as sp\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn as sk\n",
    "from collections import defaultdict\n",
    "\n",
    "try:\n",
    "    import py_entitymatching as em\n",
    "except:\n",
    "    !pip install py_entitymatching\n",
    "\n",
    "try:\n",
    "    import deepmatcher as dm\n",
    "except:\n",
    "    !pip uninstall preprocessing -y\n",
    "    !pip uninstall fastai -y \n",
    "    !pip uninstall allennlp -y\n",
    "    !pip install deepmatcher\n",
    "\n",
    "# ensuring the current pandas version is 1.2.4\n",
    "if pd.__version__ != \"1.2.4\":\n",
    " !pip install pandas==1.2.4\n",
    " import pandas as pd\n",
    " print(f\"Verify pandas=={pd.__version__}\")\n",
    "else:\n",
    " print(f\"Verify pandas=={pd.__version__}\")\n",
    "\n",
    "import sys\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.client import device_lib\n",
    "import os\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ztqswH_tmQXq"
   },
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "z6Gg_pHXqqhK",
    "outputId": "a070baf2-f7bc-40ad-dc7b-1ec1be96417b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'Dissertation_Data_2'...\n",
      "remote: Enumerating objects: 105, done.\u001b[K\n",
      "remote: Total 105 (delta 0), reused 0 (delta 0), pack-reused 105\u001b[K\n",
      "Receiving objects: 100% (105/105), 124.06 MiB | 5.10 MiB/s, done.\n",
      "Resolving deltas: 100% (46/46), done.\n",
      "Checking out files: 100% (36/36), done.\n"
     ]
    }
   ],
   "source": [
    "# retrieving the data from my GitHub\n",
    "!git clone https://github.com/ljhoh1/Dissertation_Data_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "A2YhBF_8q0tB",
    "outputId": "2b4beb7a-7820-4f0b-df39-c71c319a16b6"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:py_entitymatching.io.parsers:Metadata file is not present in the given path; proceeding to read the csv file.\n",
      "WARNING:py_entitymatching.io.parsers:Metadata file is not present in the given path; proceeding to read the csv file.\n",
      "WARNING:py_entitymatching.io.parsers:Metadata file is not present in the given path; proceeding to read the csv file.\n"
     ]
    }
   ],
   "source": [
    "# preparation for loading the data\n",
    "# Cora data (with labelled)\n",
    "path_Match = os.path.join('.', 'Dissertation_Data_2', 'DBLP-Scholar_Perfect_Mapping.csv')\n",
    "path_Match_Cora = os.path.join('.', 'Dissertation_Data_2', 'cora_duplicates_data.tsv')\n",
    "csv_table=pd.read_table(path_Match_Cora, sep='\\t')\n",
    "csv_table.to_csv(os.path.join('.', 'Dissertation_Data_2', 'cora_labelled.csv'),index=False)\n",
    "path_Cora = os.path.join('.', 'Dissertation_Data_2', 'cora_data.tsv')\n",
    "csv_table=pd.read_table(path_Cora,sep='\\t')\n",
    "csv_table.to_csv(os.path.join('.', 'Dissertation_Data_2', 'cora_data.csv'),index=False)\n",
    "\n",
    "# Scholar and DBLP data (with labelled)\n",
    "path_Scholar = os.path.join('.', 'Dissertation_Data_2', 'Scholar_data.csv')\n",
    "path_DBLP = os.path.join('.', 'Dissertation_Data_2', 'DBLP1_data.csv')\n",
    "\n",
    "Scholar = em.read_csv_metadata(path_Scholar, key='id')\n",
    "DBLP = em.read_csv_metadata(path_DBLP, key='id')\n",
    "# Load the labeled data into a dataframe.\n",
    "labelled_DS = em.read_csv_metadata(path_Match, \n",
    "                         ltable=Scholar, rtable=DBLP, \n",
    "                         fk_ltable='idScholar', fk_rtable='idDBLP')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MkhoqZYdmSa3"
   },
   "source": [
    "# Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "GbKrC9VdJB5B"
   },
   "outputs": [],
   "source": [
    "# transforming string features\n",
    "def string_cleaner(data):\n",
    "  '''\n",
    "  Creating a function to remove non-numerical/alphabetical string characters and merges features\n",
    "  Input:\n",
    "  - data (pandas DataFrame): the input data containing at least one non-identifier column\n",
    "  Output:\n",
    "  - data(pandas DataFrame): the transformed dataset\n",
    "  '''\n",
    "  # remove special characters in all features but id and cast as lower characters\n",
    "  for col in data.columns:\n",
    "    if col != \"id\":    \n",
    "      data[col] = data[col].astype(str).str.replace('[^A-Za-z0-9 ]+', '')\n",
    "      data[col] = data[col].astype(str).str.lower()\n",
    "      data.loc[data[col] == 'nan', [col]] = np.nan\n",
    "\n",
    "  #merge columns into one and remove all others\n",
    "  cols_data = [i for i in data.columns if i != \"id\"]\n",
    "  data[\"title\"] = data[cols_data].astype(str).agg(' '.join, axis=1)\n",
    "  for i in cols_data:\n",
    "    if i != \"id\" and i != \"title\":\n",
    "      del data[i]\n",
    "\n",
    "  return data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_yFtdOjBKQTv",
    "outputId": "95d75663-4f38-4fa8-b9a7-60dbf90264fe"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:py_entitymatching.io.parsers:Metadata file is not present in the given path; proceeding to read the csv file.\n",
      "WARNING:py_entitymatching.io.parsers:Metadata file is not present in the given path; proceeding to read the csv file.\n",
      "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:8: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  \n",
      "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:11: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:13: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  del sys.path[0]\n"
     ]
    }
   ],
   "source": [
    "# Loading labelled and non-labelled Cora data\n",
    "Cora = em.read_csv_metadata(os.path.join('.', 'Dissertation_Data_2', 'cora_data.csv'), key='id')\n",
    "cora_labelled = em.read_csv_metadata(os.path.join('.', 'Dissertation_Data_2', 'cora_labelled.csv'), \n",
    "                         ltable=Cora, rtable=Cora, \n",
    "                         fk_ltable='id2', fk_rtable='id1')\n",
    "\n",
    "for col in Cora.columns:\n",
    "  Cora[col] = Cora[col].astype(str).str.replace('[^A-Za-z0-9 ]+', '')\n",
    "  Cora[col] = Cora[col].astype(str).str.lower()\n",
    "\n",
    "Cora['date'] = Cora['date'].astype(str).str.replace('[^0-9]+', '')\n",
    "Cora.year.fillna(Cora.date, inplace=True)\n",
    "Cora.loc[Cora['year'] == '', ['year']] = np.nan\n",
    "del Cora['date']\n",
    "\n",
    "Cora.rename(columns = {'type':'new_type'}, inplace = True)\n",
    "\n",
    "Cora = string_cleaner(Cora)\n",
    "Scholar = string_cleaner(Scholar)\n",
    "DBLP = string_cleaner(DBLP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "fnKbu1oTp0J3"
   },
   "outputs": [],
   "source": [
    "def labelling(train, labelled, key = \"idDBLP\", val = \"idScholar\"):\n",
    "  '''\n",
    "  Create dictionary for checking how many matches are retained and perform labelling\n",
    "  Input:\n",
    "  - train (pd.DataFrame): DataFrame object of blocked data used for training\n",
    "  - lbelled (pd.DataFrame): The labelled DataFrame for labelling the train data\n",
    "  - key (string): which table id in blocked \"train\" to use as key for labelling\n",
    "  - val (string): which table id in blocked \"train\" to use as value for labelling\n",
    "  Output:\n",
    "  - train (pd.DataFrame): The labelled training dataframe\n",
    "  '''\n",
    "  # merge id columns in one to uniquely identify\n",
    "  train[\"id_comb\"] = train[\"rtable_id\"].astype(str) + train[\"ltable_id\"].astype(str)\n",
    "  labelled[\"id_comb\"] = labelled[key].astype(str) + labelled[val].astype(str)\n",
    "  # merge the training and labelled dataset and assign labels\n",
    "  K = train.merge(labelled, on='id_comb', how='left', indicator=True)\n",
    "  K.loc[(K['_merge'] == \"both\"), 'label'] = 1\n",
    "  K.loc[(K['_merge'] == \"left_only\") | (K['_merge'] == \"right_only\"), 'label'] = 0\n",
    "  # delete unused columns\n",
    "  del K['_merge']\n",
    "  del K[key]\n",
    "  del K[val]\n",
    "  del K['id_comb']\n",
    "\n",
    "  # cleaning the data\n",
    "  for col in K.columns:\n",
    "    if 'id' not in col and col != \"label\":\n",
    "      K[col] = K[col].astype(str).str.replace('[^A-Za-z0-9 ]+', '')\n",
    "  \n",
    "  if key == \"id1\":\n",
    "      K['_id'] = K['_id'].astype(int)\n",
    "  K['label'] = K['label'].astype(int)\n",
    "  return K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "7QQUfmhvvpEA"
   },
   "outputs": [],
   "source": [
    "def scores(time, predictions, iteration, train_n, model, epochs=15):\n",
    "  '''\n",
    "  Report the most important metrics of performance from the predictions made by the model\n",
    "  Input:\n",
    "  - time (float): time the model ran for\n",
    "  - predictions (pd.DataFrame): contains the output features and column \"match_score\", containing the prediction information\n",
    "  - iteration (int64): the current iteration if applicable\n",
    "  - train_n (int64): the number of samples used in training\n",
    "  - model (string): the model that was used\n",
    "  - epochs (int64): the number of epochs the model was trained for\n",
    "  Output:\n",
    "  - dict (dictionary): dictionary containing the performance information  \n",
    "  '''\n",
    "  # casting prediction scores as binary labels\n",
    "  predictions['match_prediction'] = predictions['match_score'].apply(lambda score: 1 if score >= 0.5 else 0)\n",
    "  # Reset index as Magellan requires the key to be a column in the table\n",
    "  predictions.reset_index(inplace=True)\n",
    "  # Update metadata in the catalog. This information can later be used by triggers to modify the labels from \n",
    "  # the learning-based matcher \n",
    "  em.set_key(predictions, '_id')\n",
    "  em.set_fk_ltable(predictions, 'ltable_id')\n",
    "  em.set_fk_rtable(predictions, 'rtable_id')\n",
    "  # AUC-ROC metrics\n",
    "  auc = sk.metrics.roc_auc_score(predictions['label'], predictions['match_score'], average = None)\n",
    "  # Precision Metrics\n",
    "  prec = em.eval_matches(predictions, 'label', 'match_prediction')\n",
    "  # Creating dictionary of performance metrics to append to a DataFrame\n",
    "  dict = {'Model':model, 'Time':time, 'Epochs':epochs,'Iteration':iteration, '#Training_samples':train_n,\n",
    "                          'F1':prec['f1'], 'Precision':prec['precision'], \n",
    "                          'Recall':prec['recall'], 'AUC':auc}\n",
    "  return dict\n",
    "# Create a placeholder matrix to append precision scores to\n",
    "prec_matrix = pd.DataFrame(columns=['Model', 'Time', 'Epochs', 'Iteration', '#Training_samples', 'F1', 'Precision', 'Recall', 'AUC'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "la3CZwreS35t"
   },
   "outputs": [],
   "source": [
    "def subsampling(cand):\n",
    "  '''\n",
    "  Function to subsample to avoid unbalanced data\n",
    "  Input:\n",
    "  - cand (pd.DataFrame): contains the blocked (and transformed) data with \"label\" feature\n",
    "  Output:\n",
    "  - cand_resampled (pd.DataFrame): contains the resampled data to avoid imbalance\n",
    "  '''\n",
    "  # subsampling the candidate set for better balance\n",
    "  # creating the explanatory and dependent feature data\n",
    "  binary_X = cand.loc[:, cand.columns != \"label\"]\n",
    "  binary_y = cand.loc[:, cand.columns == \"label\"]\n",
    "  # initialising the RandomUnderSampler\n",
    "  rus = RandomUnderSampler(random_state=0)\n",
    "  # resampling to 0.5/0.5\n",
    "  X_res, y_res = rus.fit_resample(binary_X, binary_y)\n",
    "  res_labelled = pd.DataFrame(X_res)\n",
    "  res_labelled.columns = cand.columns[0:-1]\n",
    "  # take the index of resampled observations to subsample from the original\n",
    "  sel_idx = list(res_labelled._id)\n",
    "  cand_resampled = cand[cand[\"_id\"].isin(sel_idx)]\n",
    "  return cand_resampled"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "--ZBsw9SmXWu"
   },
   "source": [
    "# Blocking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "yRZdKRmdEorb"
   },
   "outputs": [],
   "source": [
    "# feature blocking for Cora \n",
    "# Get tokenizers and similarity function\n",
    "block_t = em.get_tokenizers_for_blocking()\n",
    "block_s = em.get_sim_funs_for_blocking()\n",
    "# Get attributes\n",
    "atypes1 = em.get_attr_types(Cora)\n",
    "atypes2 = em.get_attr_types(Cora)\n",
    "# Get correspondence\n",
    "block_c = em.get_attr_corres(Cora, Cora)\n",
    "#Get Features\n",
    "block_f = em.get_features(Cora, Cora, atypes1, atypes2, block_c, block_t, block_s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8oSqele6wfPB",
    "outputId": "950b0ee4-b2d4-42eb-e016-4ced7d4dee19"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0% [##############################] 100% | ETA: 00:00:00\n",
      "Total time elapsed: 00:00:05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finding pairs with missing value...\n"
     ]
    }
   ],
   "source": [
    "# Creating a rule based blocker with threshold 0.4\n",
    "rb = em.RuleBasedBlocker()\n",
    "cols_cora = [i for i in Cora.columns]\n",
    "rule = ['title_title_jac_qgm_3_qgm_3(ltuple, rtuple) < 0.3']\n",
    "rb.add_rule(rule, feature_table=block_f)\n",
    "K1 = rb.block_tables(Cora, Cora,\n",
    "                   l_output_attrs=cols_cora, \n",
    "                   r_output_attrs=cols_cora,\n",
    "                   n_jobs=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CvUSG529mrXu"
   },
   "source": [
    "# Processing and Modell Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9c_HswRHxP3Q"
   },
   "source": [
    "## Cora"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "akRo4SO__4G5"
   },
   "source": [
    "### Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "g3dd1_oaqvqz",
    "outputId": "5ad9b70f-3013-4d6b-82d9-df4d9da77b61"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:28: FutureWarning: The default value of regex will change from True to False in a future version.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Proportion of matches retained after blocking: 1.0\n"
     ]
    }
   ],
   "source": [
    "cols = list(cora_labelled.columns)\n",
    "a, b = cols.index('id1'), cols.index('id2')\n",
    "cols[b], cols[a] = cols[a], cols[b]\n",
    "cor_lab_rev = cora_labelled[cols]\n",
    "cor_lab_rev.columns = ['id1', 'id2']\n",
    "cora_labelled = cora_labelled.append(cor_lab_rev)\n",
    "# Labelling the blocked data set\n",
    "cand = labelling(K1, cora_labelled, key = \"id1\", val = \"id2\")\n",
    "print(\"Proportion of matches retained after blocking:\", round(sum(cand['label']) / cora_labelled.shape[0], 2))\n",
    "\n",
    "#cand_resampled = subsampling(cand)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "OZ8HQQ6ssFAX"
   },
   "outputs": [],
   "source": [
    "#pred.to_csv(os.path.join('.', 'Dissertation_Data_2', 'pred_Cora.csv'),index=False)\n",
    "# The directory where the data splits will be saved.\n",
    "split_path = os.path.join('.', 'Dissertation_Data_2')\n",
    "# Split labeled data into train, valid, and test csv files to disk, with the split ratio of 3:1:1.\n",
    "dm.data.split(cand, split_path, 'train.csv', 'valid.csv', 'test.csv',\n",
    "              [3, 1, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AshNssGUQLsS",
    "outputId": "c6e5e5ff-5ffb-42ea-f032-ac9edcf74392"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(233183, 6)"
      ]
     },
     "execution_count": 13,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cand.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lENend5UL2vb",
    "outputId": "7d2c4db7-d08d-48ae-bdda-8e2cba724d0c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "129109"
      ]
     },
     "execution_count": 14,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(cand['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "y4bKrSff5rtg"
   },
   "outputs": [],
   "source": [
    "# The directory where the data splits will be saved.\n",
    "split_path = os.path.join('.', 'Dissertation_Data_2')\n",
    "# Split labeled data into train, valid, and test csv files to disk, with the split ratio of 3:1:1.\n",
    "dm.data.split(cand, split_path, 'train.csv', 'valid.csv', 'test.csv',\n",
    "              [3, 1, 1],\n",
    "              stratified=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Y9-lRVe_qc-O",
    "outputId": "9bfacd2d-8414-4424-9342-6b048e915984"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Proportion of matches retained after blocking: 0.55\n"
     ]
    }
   ],
   "source": [
    "print(\"Proportion of matches retained after blocking:\", round(sum(cand['label']) / cand.shape[0], 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PHQtZpzUsO8G",
    "outputId": "9251a6aa-a3c3-420d-f089-4f47f633b2a7"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Reading and processing data from \"./Dissertation_Data_2/train.csv\"\n",
      "0% [##############################] 100% | ETA: 00:00:00\n",
      "Reading and processing data from \"./Dissertation_Data_2/valid.csv\"\n",
      "0% [##############################] 100% | ETA: 00:00:00\n",
      "Reading and processing data from \"./Dissertation_Data_2/test.csv\"\n",
      "0% [##############################] 100% | ETA: 00:00:00INFO:deepmatcher.data.field:Downloading vectors from https://drive.google.com/uc?export=download&id=1Vih8gAmgBnuYDxfblbT94P6WjB7s1ZSh to /root/.vector_cache/wiki.en.bin\n",
      "INFO:deepmatcher.data.field:Unable to fetch cached English Word Embeddings from https://drive.google.com/uc?export=download&id=1Vih8gAmgBnuYDxfblbT94P6WjB7s1ZSh\n",
      "Downloading embeddings from https://dl.fbaipublicfiles.com/fasttext/vectors-wiki/wiki.en.zip to /root/.vector_cache/wiki.en.zip\n",
      "/usr/local/lib/python3.7/dist-packages/deepmatcher/data/field.py:79: ResourceWarning: unclosed <ssl.SSLSocket fd=64, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('172.28.0.2', 56970), raddr=('173.194.76.100', 443)>\n",
      "  self.destination = self.backup_destination\n",
      "ResourceWarning: Enable tracemalloc to get the object allocation traceback\n",
      "INFO:deepmatcher.data.field:Extracting vectors into /root/.vector_cache\n",
      "Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\n",
      "\n",
      "Building vocabulary\n",
      "0% [##############################] 100% | ETA: 00:00:00\n",
      "Total time elapsed: 00:00:06\n",
      "\n",
      "Computing principal components\n",
      "0% [##############################] 100% | ETA: 00:00:00\n",
      "Total time elapsed: 00:00:53\n"
     ]
    }
   ],
   "source": [
    "# Load the training data files from the disk. Ignore the \"left_id\" and \"right_id\" \n",
    "# columns for data preprocessing.\n",
    "# The 'use_magellan_convention' parameter asks deepmatcher to use Magellan's \n",
    "# naming convention for the left and right table column name prefixes \n",
    "# (\"ltable_\", and \"rtable_\"), and also to consider \"_id\" as the ID column.\n",
    "train, validation, test = dm.data.process(\n",
    "    path=os.path.join('.', 'Dissertation_Data_2'),\n",
    "    cache='train_cache_4.pth',\n",
    "    train='train.csv',\n",
    "    validation='valid.csv',\n",
    "    test='test.csv',\n",
    "    use_magellan_convention=True,\n",
    "    ignore_columns=('ltable_id', 'rtable_id'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hCs2j9oy_1UO"
   },
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9YT0_X8GOsI8",
    "outputId": "268fec12-0d68-43ae-b3c7-9732d27b2b61"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py:949: UserWarning: Using non-full backward hooks on a Module that does not take as input a single Tensor or a tuple of Tensors is deprecated and will be removed in future versions. This hook will be missing some of the grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
      "  warnings.warn(\"Using non-full backward hooks on a Module that does not take as input a \"\n",
      "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py:974: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
      "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Number of trainable parameters: 2798703\n",
      "===>  TRAIN Epoch 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py:939: UserWarning: Using non-full backward hooks on a Module that does not return a single Tensor or a tuple of Tensors is deprecated and will be removed in future versions. This hook will be missing some of the grad_output. Please use register_full_backward_hook to get the documented behavior.\n",
      "  warnings.warn(\"Using non-full backward hooks on a Module that does not return a \"\n",
      "/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2742: UserWarning: reduction: 'mean' divides the total loss by both the batch size and the support size.'batchmean' divides only by the batch size, and aligns with the KL div math definition.'mean' will be changed to behave the same as 'batchmean' in the next major release.\n",
      "  \"reduction: 'mean' divides the total loss by both the batch size and the support size.\"\n",
      "0% [██████████████████████████████] 100% | ETA: 00:00:00\n",
      "Total time elapsed: 00:06:58\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Epoch 1 || Run Time:  141.7 | Load Time:  278.6 || F1:  97.87 | Prec:  97.15 | Rec:  98.61 || Ex/s: 332.84\n",
      "\n",
      "===>  EVAL Epoch 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0% [██████████████████████████████] 100% | ETA: 00:00:00\n",
      "Total time elapsed: 00:01:44\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Epoch 1 || Run Time:   18.0 | Load Time:   86.8 || F1:  99.28 | Prec:  98.76 | Rec:  99.79 || Ex/s: 445.35\n",
      "\n",
      "* Best F1: tensor(99.2757, device='cuda:0')\n",
      "Saving best model...\n",
      "Done.\n",
      "---------------------\n",
      "\n",
      "===>  TRAIN Epoch 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0% [██████████████████████████████] 100% | ETA: 00:00:00\n",
      "Total time elapsed: 00:06:58\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Epoch 2 || Run Time:  141.9 | Load Time:  278.7 || F1:  99.25 | Prec:  98.74 | Rec:  99.76 || Ex/s: 332.59\n",
      "\n",
      "===>  EVAL Epoch 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0% [██████████████████████████████] 100% | ETA: 00:00:00\n",
      "Total time elapsed: 00:01:44\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Epoch 2 || Run Time:   17.9 | Load Time:   86.8 || F1:  99.26 | Prec:  99.04 | Rec:  99.48 || Ex/s: 445.29\n",
      "\n",
      "---------------------\n",
      "\n",
      "===>  TRAIN Epoch 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0% [██████████████████████████████] 100% | ETA: 00:00:00\n",
      "Total time elapsed: 00:06:58\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Epoch 3 || Run Time:  141.5 | Load Time:  278.9 || F1:  99.27 | Prec:  98.85 | Rec:  99.70 || Ex/s: 332.80\n",
      "\n",
      "===>  EVAL Epoch 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0% [██████████████████████████████] 100% | ETA: 00:00:00\n",
      "Total time elapsed: 00:01:44\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Epoch 3 || Run Time:   18.0 | Load Time:   86.9 || F1:  99.28 | Prec:  99.19 | Rec:  99.38 || Ex/s: 444.80\n",
      "\n",
      "* Best F1: tensor(99.2823, device='cuda:0')\n",
      "Saving best model...\n",
      "Done.\n",
      "---------------------\n",
      "\n",
      "===>  TRAIN Epoch 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0% [██████████████████████████████] 100% | ETA: 00:00:00\n",
      "Total time elapsed: 00:06:58\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Epoch 4 || Run Time:  141.5 | Load Time:  278.4 || F1:  99.31 | Prec:  98.96 | Rec:  99.67 || Ex/s: 333.17\n",
      "\n",
      "===>  EVAL Epoch 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0% [██████████████████████████████] 100% | ETA: 00:00:00\n",
      "Total time elapsed: 00:01:44\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Epoch 4 || Run Time:   17.9 | Load Time:   86.3 || F1:  99.32 | Prec:  99.23 | Rec:  99.40 || Ex/s: 447.57\n",
      "\n",
      "* Best F1: tensor(99.3171, device='cuda:0')\n",
      "Saving best model...\n",
      "Done.\n",
      "---------------------\n",
      "\n",
      "===>  TRAIN Epoch 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0% [██████████████████████████████] 100% | ETA: 00:00:00\n",
      "Total time elapsed: 00:06:58\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Epoch 5 || Run Time:  141.4 | Load Time:  278.5 || F1:  99.36 | Prec:  99.03 | Rec:  99.69 || Ex/s: 333.14\n",
      "\n",
      "===>  EVAL Epoch 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0% [██████████████████████████████] 100% | ETA: 00:00:00\n",
      "Total time elapsed: 00:01:44\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Epoch 5 || Run Time:   17.9 | Load Time:   86.7 || F1:  99.31 | Prec:  99.20 | Rec:  99.43 || Ex/s: 445.51\n",
      "\n",
      "---------------------\n",
      "\n",
      "===>  TRAIN Epoch 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0% [██████████████████████████████] 100% | ETA: 00:00:00\n",
      "Total time elapsed: 00:06:58\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Epoch 6 || Run Time:  141.5 | Load Time:  278.5 || F1:  99.39 | Prec:  99.09 | Rec:  99.70 || Ex/s: 333.12\n",
      "\n",
      "===>  EVAL Epoch 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0% [██████████████████████████████] 100% | ETA: 00:00:00\n",
      "Total time elapsed: 00:01:44\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Epoch 6 || Run Time:   18.0 | Load Time:   86.7 || F1:  99.32 | Prec:  99.20 | Rec:  99.43 || Ex/s: 445.83\n",
      "\n",
      "---------------------\n",
      "\n",
      "===>  TRAIN Epoch 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0% [██████████████████████████████] 100% | ETA: 00:00:00\n",
      "Total time elapsed: 00:06:58\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Epoch 7 || Run Time:  141.5 | Load Time:  278.2 || F1:  99.41 | Prec:  99.12 | Rec:  99.71 || Ex/s: 333.31\n",
      "\n",
      "===>  EVAL Epoch 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0% [██████████████████████████████] 100% | ETA: 00:00:00\n",
      "Total time elapsed: 00:01:44\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Epoch 7 || Run Time:   17.9 | Load Time:   86.9 || F1:  99.34 | Prec:  99.16 | Rec:  99.53 || Ex/s: 444.77\n",
      "\n",
      "* Best F1: tensor(99.3448, device='cuda:0')\n",
      "Saving best model...\n",
      "Done.\n",
      "---------------------\n",
      "\n",
      "===>  TRAIN Epoch 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0% [██████████████████████████████] 100% | ETA: 00:00:00\n",
      "Total time elapsed: 00:06:58\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Epoch 8 || Run Time:  141.6 | Load Time:  278.7 || F1:  99.43 | Prec:  99.14 | Rec:  99.72 || Ex/s: 332.91\n",
      "\n",
      "===>  EVAL Epoch 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0% [██████████████████████████████] 100% | ETA: 00:00:00\n",
      "Total time elapsed: 00:01:44\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Epoch 8 || Run Time:   17.9 | Load Time:   86.8 || F1:  99.36 | Prec:  99.16 | Rec:  99.56 || Ex/s: 445.45\n",
      "\n",
      "* Best F1: tensor(99.3585, device='cuda:0')\n",
      "Saving best model...\n",
      "Done.\n",
      "---------------------\n",
      "\n",
      "===>  TRAIN Epoch 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0% [██████████████████████████████] 100% | ETA: 00:00:00\n",
      "Total time elapsed: 00:06:57\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Epoch 9 || Run Time:  141.4 | Load Time:  278.3 || F1:  99.44 | Prec:  99.15 | Rec:  99.73 || Ex/s: 333.36\n",
      "\n",
      "===>  EVAL Epoch 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0% [██████████████████████████████] 100% | ETA: 00:00:00\n",
      "Total time elapsed: 00:01:44\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Epoch 9 || Run Time:   18.0 | Load Time:   86.8 || F1:  99.36 | Prec:  99.15 | Rec:  99.57 || Ex/s: 444.99\n",
      "\n",
      "* Best F1: tensor(99.3585, device='cuda:0')\n",
      "Saving best model...\n",
      "Done.\n",
      "---------------------\n",
      "\n",
      "===>  TRAIN Epoch 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0% [██████████████████████████████] 100% | ETA: 00:00:00\n",
      "Total time elapsed: 00:06:58\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Epoch 10 || Run Time:  141.7 | Load Time:  278.5 || F1:  99.47 | Prec:  99.19 | Rec:  99.74 || Ex/s: 332.94\n",
      "\n",
      "===>  EVAL Epoch 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0% [██████████████████████████████] 100% | ETA: 00:00:00\n",
      "Total time elapsed: 00:01:44\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Epoch 10 || Run Time:   17.9 | Load Time:   86.7 || F1:  99.35 | Prec:  99.16 | Rec:  99.55 || Ex/s: 445.77\n",
      "\n",
      "---------------------\n",
      "\n",
      "===>  TRAIN Epoch 11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0% [██████████████████████████████] 100% | ETA: 00:00:00\n",
      "Total time elapsed: 00:06:57\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Epoch 11 || Run Time:  141.4 | Load Time:  278.1 || F1:  99.48 | Prec:  99.21 | Rec:  99.75 || Ex/s: 333.51\n",
      "\n",
      "===>  EVAL Epoch 11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0% [██████████████████████████████] 100% | ETA: 00:00:00\n",
      "Total time elapsed: 00:01:44\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Epoch 11 || Run Time:   17.9 | Load Time:   86.6 || F1:  99.35 | Prec:  99.12 | Rec:  99.57 || Ex/s: 446.36\n",
      "\n",
      "---------------------\n",
      "\n",
      "===>  TRAIN Epoch 12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0% [██████████████████████████████] 100% | ETA: 00:00:00\n",
      "Total time elapsed: 00:06:58\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Epoch 12 || Run Time:  141.5 | Load Time:  278.6 || F1:  99.49 | Prec:  99.22 | Rec:  99.77 || Ex/s: 333.05\n",
      "\n",
      "===>  EVAL Epoch 12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0% [██████████████████████████████] 100% | ETA: 00:00:00\n",
      "Total time elapsed: 00:01:44\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Epoch 12 || Run Time:   17.9 | Load Time:   86.8 || F1:  99.35 | Prec:  99.10 | Rec:  99.59 || Ex/s: 445.38\n",
      "\n",
      "---------------------\n",
      "\n",
      "===>  TRAIN Epoch 13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0% [██████████████████████████████] 100% | ETA: 00:00:00\n",
      "Total time elapsed: 00:06:58\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Epoch 13 || Run Time:  141.5 | Load Time:  278.2 || F1:  99.50 | Prec:  99.22 | Rec:  99.78 || Ex/s: 333.32\n",
      "\n",
      "===>  EVAL Epoch 13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0% [██████████████████████████████] 100% | ETA: 00:00:00\n",
      "Total time elapsed: 00:01:44\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Epoch 13 || Run Time:   18.0 | Load Time:   86.7 || F1:  99.33 | Prec:  99.08 | Rec:  99.59 || Ex/s: 445.37\n",
      "\n",
      "---------------------\n",
      "\n",
      "===>  TRAIN Epoch 14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0% [██████████████████████████████] 100% | ETA: 00:00:00\n",
      "Total time elapsed: 00:06:58\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Epoch 14 || Run Time:  141.7 | Load Time:  278.6 || F1:  99.51 | Prec:  99.23 | Rec:  99.80 || Ex/s: 332.86\n",
      "\n",
      "===>  EVAL Epoch 14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0% [██████████████████████████████] 100% | ETA: 00:00:00\n",
      "Total time elapsed: 00:01:44\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Epoch 14 || Run Time:   17.9 | Load Time:   87.1 || F1:  99.34 | Prec:  99.06 | Rec:  99.63 || Ex/s: 444.16\n",
      "\n",
      "---------------------\n",
      "\n",
      "===>  TRAIN Epoch 15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0% [██████████████████████████████] 100% | ETA: 00:00:00\n",
      "Total time elapsed: 00:06:58\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Epoch 15 || Run Time:  141.5 | Load Time:  278.6 || F1:  99.52 | Prec:  99.23 | Rec:  99.80 || Ex/s: 333.11\n",
      "\n",
      "===>  EVAL Epoch 15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0% [██████████████████████████████] 100% | ETA: 00:00:00\n",
      "Total time elapsed: 00:01:44\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Epoch 15 || Run Time:   17.9 | Load Time:   86.9 || F1:  99.34 | Prec:  99.03 | Rec:  99.64 || Ex/s: 444.99\n",
      "\n",
      "---------------------\n",
      "\n",
      "Loading best model...\n",
      "Training done.\n",
      "===>  EVAL Epoch 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0% [██████████████████████████████] 100% | ETA: 00:00:00\n",
      "Total time elapsed: 00:01:50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Epoch 9 || Run Time:   39.5 | Load Time:   71.3 || F1:  99.34 | Prec:  99.16 | Rec:  99.52 || Ex/s: 421.14\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(99.3389, device='cuda:0')"
      ]
     },
     "execution_count": 18,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a hybrid model.\n",
    "model_cor = dm.MatchingModel(attr_summarizer='hybrid')\n",
    "model_cor.initialize(train)  # Initilization\n",
    "\n",
    "# Train ing model on 10 epochs, batch size of 16, positive-to-negative \n",
    "# ratio to be 1:1. We save the best model (with the \n",
    "# highest F1 score on the validation set) to 'sifDiff_model.pth'.\n",
    "startTime = time.time()\n",
    "model_cor.run_train(\n",
    "    train,\n",
    "    validation,\n",
    "    epochs=15,\n",
    "    batch_size=128,\n",
    "    best_save_path='hybrid_Trans_Cor.pth')\n",
    "executionTime_Cora = (time.time() - startTime)/60\n",
    "# Evaluate the accuracy on the test data.\n",
    "model_cor.run_eval(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gbQSdtqbxVTX"
   },
   "source": [
    "## Scholar-DBLP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hH3oFv3l_-4f"
   },
   "source": [
    "### Process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "UxStmOLM5_fa"
   },
   "outputs": [],
   "source": [
    "# blocking for predictions on other data set\n",
    "# Get tokenizers and similarity function\n",
    "block_t = em.get_tokenizers_for_blocking()\n",
    "block_s = em.get_sim_funs_for_blocking()\n",
    "# Get attributes\n",
    "atypes1 = em.get_attr_types(Scholar)\n",
    "atypes2 = em.get_attr_types(DBLP)\n",
    "# Get correspondence\n",
    "block_c = em.get_attr_corres(Scholar, DBLP)\n",
    "#Get Features\n",
    "block_f = em.get_features(Scholar, DBLP, atypes1, atypes2, block_c, block_t, block_s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4nONYq1UMyFg",
    "outputId": "31fd4344-c273-4055-b569-84a48b9e4e84"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0% [##############################] 100% | ETA: 00:00:00"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finding pairs with missing value...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Total time elapsed: 00:02:25\n"
     ]
    }
   ],
   "source": [
    "# Creating a rule based blocker for prediction\n",
    "rb = em.RuleBasedBlocker()\n",
    "# 0.3 achieves 49% balance negative to positive\n",
    "rule = ['title_title_jac_qgm_3_qgm_3(ltuple, rtuple) < 0.3']\n",
    "rb.add_rule(rule, feature_table=block_f)\n",
    "C = rb.block_tables(Scholar, DBLP,\n",
    "                   l_output_attrs=['title'], \n",
    "                   r_output_attrs=['title'], \n",
    "                   n_jobs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cTG1sFf8OC6h",
    "outputId": "4e6defce-ebca-4f9e-adb2-7a417a298e9d"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:28: FutureWarning: The default value of regex will change from True to False in a future version.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Proportion of matches retained after blocking: 0.98\n"
     ]
    }
   ],
   "source": [
    "# labelling data for prediction\n",
    "pred = labelling(C, labelled_DS, key = \"idDBLP\", val = \"idScholar\")\n",
    "print(\"Proportion of matches retained after blocking:\", round(sum(pred['label']) / labelled_DS.shape[0], 2))\n",
    "\n",
    "pred.to_csv(os.path.join('.', 'Dissertation_Data_2', 'pred_DS.csv'),index=False)\n",
    "# The directory where the data splits will be saved.\n",
    "split_path = os.path.join('.', 'Dissertation_Data_2')\n",
    "# Split labeled data into train, valid, and test csv files to disk, with the split ratio of 3:1:1.\n",
    "dm.data.split(pred, split_path, 'train_DS.csv', 'valid_DS.csv', 'test_DS.csv',\n",
    "              [3, 1, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ul931vn44APM",
    "outputId": "cb7362de-96f8-426b-d146-197a571c4605"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11322, 6)"
      ]
     },
     "execution_count": 22,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hIWzd_RbnjmN",
    "outputId": "545a7201-cfc9-46fb-dff3-849d7f6b5d52"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Reading and processing data from \"./Dissertation_Data_2/train_DS.csv\"\n",
      "0% [############################# ] 100% | ETA: 00:00:00\n",
      "Reading and processing data from \"./Dissertation_Data_2/valid_DS.csv\"\n",
      "0% [############################# ] 100% | ETA: 00:00:00\n",
      "Reading and processing data from \"./Dissertation_Data_2/test_DS.csv\"\n",
      "0% [############################# ] 100% | ETA: 00:00:00\n",
      "Building vocabulary\n",
      "0% [#######] 100% | ETA: 00:00:00\n",
      "Total time elapsed: 00:00:00\n",
      "\n",
      "Computing principal components\n",
      "0% [#######] 100% | ETA: 00:00:00\n",
      "Total time elapsed: 00:00:01\n",
      "\n",
      "Reading and processing data from \"./Dissertation_Data_2/train_DS.csv\"\n",
      "0% [############################# ] 100% | ETA: 00:00:00\n",
      "Reading and processing data from \"./Dissertation_Data_2/valid_DS.csv\"\n",
      "0% [############################# ] 100% | ETA: 00:00:00\n",
      "Reading and processing data from \"./Dissertation_Data_2/pred_DS.csv\"\n",
      "0% [############################# ] 100% | ETA: 00:00:00\n",
      "Building vocabulary\n",
      "0% [#######] 100% | ETA: 00:00:00\n",
      "Total time elapsed: 00:00:00\n",
      "\n",
      "Computing principal components\n",
      "0% [#######] 100% | ETA: 00:00:00\n",
      "Total time elapsed: 00:00:01\n"
     ]
    }
   ],
   "source": [
    "# processing the data for prediction\n",
    "train_DS, validation_DS, test_DS = dm.data.process(\n",
    "    path=os.path.join('.', 'Dissertation_Data_2'),\n",
    "    cache='train_cache_2.pth',\n",
    "    train='train_DS.csv',\n",
    "    validation='valid_DS.csv',\n",
    "    test='test_DS.csv',\n",
    "    use_magellan_convention=True,\n",
    "    ignore_columns=('ltable_id', 'rtable_id'))\n",
    "\n",
    "train_DS, validation_DS, pred_DS = dm.data.process(\n",
    "    path=os.path.join('.', 'Dissertation_Data_2'),\n",
    "    cache='train_cache_3.pth',\n",
    "    train='train_DS.csv',\n",
    "    validation='valid_DS.csv',\n",
    "    test='pred_DS.csv',\n",
    "    use_magellan_convention=True,\n",
    "    ignore_columns=('ltable_id', 'rtable_id'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "W1AeyxP3ABkM"
   },
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2WOFtL7kRckt",
    "outputId": "e99bcf79-5d77-420b-a0d5-a1c93fdc8b9f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Number of trainable parameters: 2798703\n",
      "===>  TRAIN Epoch 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py:949: UserWarning: Using non-full backward hooks on a Module that does not take as input a single Tensor or a tuple of Tensors is deprecated and will be removed in future versions. This hook will be missing some of the grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
      "  warnings.warn(\"Using non-full backward hooks on a Module that does not take as input a \"\n",
      "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py:974: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
      "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n",
      "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py:939: UserWarning: Using non-full backward hooks on a Module that does not return a single Tensor or a tuple of Tensors is deprecated and will be removed in future versions. This hook will be missing some of the grad_output. Please use register_full_backward_hook to get the documented behavior.\n",
      "  warnings.warn(\"Using non-full backward hooks on a Module that does not return a \"\n",
      "/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2742: UserWarning: reduction: 'mean' divides the total loss by both the batch size and the support size.'batchmean' divides only by the batch size, and aligns with the KL div math definition.'mean' will be changed to behave the same as 'batchmean' in the next major release.\n",
      "  \"reduction: 'mean' divides the total loss by both the batch size and the support size.\"\n",
      "0% [██████████████████████████████] 100% | ETA: 00:00:00\n",
      "Total time elapsed: 00:00:24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Epoch 1 || Run Time:   18.2 | Load Time:    6.0 || F1:  85.72 | Prec:  84.45 | Rec:  87.03 || Ex/s: 279.73\n",
      "\n",
      "===>  EVAL Epoch 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0% [████████████████████████████] 100% | ETA: 00:00:00\n",
      "Total time elapsed: 00:00:05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Epoch 1 || Run Time:    3.0 | Load Time:    2.1 || F1:  92.39 | Prec:  91.23 | Rec:  93.59 || Ex/s: 443.37\n",
      "\n",
      "* Best F1: tensor(92.3949, device='cuda:0')\n",
      "Saving best model...\n",
      "Done.\n",
      "---------------------\n",
      "\n",
      "===>  TRAIN Epoch 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0% [██████████████████████████████] 100% | ETA: 00:00:00\n",
      "Total time elapsed: 00:00:24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Epoch 2 || Run Time:   18.1 | Load Time:    6.0 || F1:  94.28 | Prec:  94.22 | Rec:  94.34 || Ex/s: 281.87\n",
      "\n",
      "===>  EVAL Epoch 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0% [████████████████████████████] 100% | ETA: 00:00:00\n",
      "Total time elapsed: 00:00:04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Epoch 2 || Run Time:    3.0 | Load Time:    2.1 || F1:  92.73 | Prec:  91.52 | Rec:  93.97 || Ex/s: 449.18\n",
      "\n",
      "* Best F1: tensor(92.7290, device='cuda:0')\n",
      "Saving best model...\n",
      "Done.\n",
      "---------------------\n",
      "\n",
      "===>  TRAIN Epoch 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0% [██████████████████████████████] 100% | ETA: 00:00:00\n",
      "Total time elapsed: 00:00:24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Epoch 3 || Run Time:   18.3 | Load Time:    6.1 || F1:  96.07 | Prec:  95.88 | Rec:  96.25 || Ex/s: 278.46\n",
      "\n",
      "===>  EVAL Epoch 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0% [████████████████████████████] 100% | ETA: 00:00:00\n",
      "Total time elapsed: 00:00:04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Epoch 3 || Run Time:    3.0 | Load Time:    2.0 || F1:  93.13 | Prec:  91.04 | Rec:  95.31 || Ex/s: 451.18\n",
      "\n",
      "* Best F1: tensor(93.1276, device='cuda:0')\n",
      "Saving best model...\n",
      "Done.\n",
      "---------------------\n",
      "\n",
      "===>  TRAIN Epoch 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0% [██████████████████████████████] 100% | ETA: 00:00:00\n",
      "Total time elapsed: 00:00:24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Epoch 4 || Run Time:   18.1 | Load Time:    6.0 || F1:  97.41 | Prec:  97.48 | Rec:  97.33 || Ex/s: 281.62\n",
      "\n",
      "===>  EVAL Epoch 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0% [████████████████████████████] 100% | ETA: 00:00:00\n",
      "Total time elapsed: 00:00:05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Epoch 4 || Run Time:    3.0 | Load Time:    2.1 || F1:  93.58 | Prec:  91.65 | Rec:  95.60 || Ex/s: 446.30\n",
      "\n",
      "* Best F1: tensor(93.5831, device='cuda:0')\n",
      "Saving best model...\n",
      "Done.\n",
      "---------------------\n",
      "\n",
      "===>  TRAIN Epoch 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0% [██████████████████████████████] 100% | ETA: 00:00:00\n",
      "Total time elapsed: 00:00:24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Epoch 5 || Run Time:   18.2 | Load Time:    6.0 || F1:  97.98 | Prec:  98.24 | Rec:  97.71 || Ex/s: 280.31\n",
      "\n",
      "===>  EVAL Epoch 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0% [████████████████████████████] 100% | ETA: 00:00:00\n",
      "Total time elapsed: 00:00:04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Epoch 5 || Run Time:    3.0 | Load Time:    2.1 || F1:  93.81 | Prec:  92.71 | Rec:  94.93 || Ex/s: 447.07\n",
      "\n",
      "* Best F1: tensor(93.8061, device='cuda:0')\n",
      "Saving best model...\n",
      "Done.\n",
      "---------------------\n",
      "\n",
      "===>  TRAIN Epoch 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0% [██████████████████████████████] 100% | ETA: 00:00:00\n",
      "Total time elapsed: 00:00:24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Epoch 6 || Run Time:   18.1 | Load Time:    6.0 || F1:  98.89 | Prec:  99.07 | Rec:  98.70 || Ex/s: 281.39\n",
      "\n",
      "===>  EVAL Epoch 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0% [████████████████████████████] 100% | ETA: 00:00:00\n",
      "Total time elapsed: 00:00:04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Epoch 6 || Run Time:    3.0 | Load Time:    2.1 || F1:  93.95 | Prec:  92.17 | Rec:  95.79 || Ex/s: 450.34\n",
      "\n",
      "* Best F1: tensor(93.9465, device='cuda:0')\n",
      "Saving best model...\n",
      "Done.\n",
      "---------------------\n",
      "\n",
      "===>  TRAIN Epoch 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0% [██████████████████████████████] 100% | ETA: 00:00:00\n",
      "Total time elapsed: 00:00:24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Epoch 7 || Run Time:   18.2 | Load Time:    6.0 || F1:  99.28 | Prec:  99.55 | Rec:  99.01 || Ex/s: 280.51\n",
      "\n",
      "===>  EVAL Epoch 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0% [████████████████████████████] 100% | ETA: 00:00:00\n",
      "Total time elapsed: 00:00:05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Epoch 7 || Run Time:    3.0 | Load Time:    2.1 || F1:  93.78 | Prec:  93.03 | Rec:  94.55 || Ex/s: 445.87\n",
      "\n",
      "---------------------\n",
      "\n",
      "===>  TRAIN Epoch 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0% [██████████████████████████████] 100% | ETA: 00:00:00\n",
      "Total time elapsed: 00:00:24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Epoch 8 || Run Time:   18.2 | Load Time:    6.0 || F1:  99.52 | Prec:  99.78 | Rec:  99.27 || Ex/s: 280.71\n",
      "\n",
      "===>  EVAL Epoch 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0% [████████████████████████████] 100% | ETA: 00:00:00\n",
      "Total time elapsed: 00:00:05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Epoch 8 || Run Time:    3.0 | Load Time:    2.1 || F1:  93.69 | Prec:  92.22 | Rec:  95.22 || Ex/s: 445.92\n",
      "\n",
      "---------------------\n",
      "\n",
      "===>  TRAIN Epoch 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0% [██████████████████████████████] 100% | ETA: 00:00:00\n",
      "Total time elapsed: 00:00:23\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Epoch 9 || Run Time:   18.0 | Load Time:    6.0 || F1:  99.59 | Prec:  99.84 | Rec:  99.33 || Ex/s: 283.56\n",
      "\n",
      "===>  EVAL Epoch 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0% [████████████████████████████] 100% | ETA: 00:00:00\n",
      "Total time elapsed: 00:00:05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Epoch 9 || Run Time:    3.0 | Load Time:    2.1 || F1:  93.57 | Prec:  93.09 | Rec:  94.07 || Ex/s: 441.40\n",
      "\n",
      "---------------------\n",
      "\n",
      "===>  TRAIN Epoch 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0% [██████████████████████████████] 100% | ETA: 00:00:00\n",
      "Total time elapsed: 00:00:24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Epoch 10 || Run Time:   18.2 | Load Time:    6.0 || F1:  99.67 | Prec:  99.90 | Rec:  99.43 || Ex/s: 279.89\n",
      "\n",
      "===>  EVAL Epoch 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0% [████████████████████████████] 100% | ETA: 00:00:00\n",
      "Total time elapsed: 00:00:04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Epoch 10 || Run Time:    3.0 | Load Time:    2.1 || F1:  93.70 | Prec:  93.52 | Rec:  93.88 || Ex/s: 448.22\n",
      "\n",
      "---------------------\n",
      "\n",
      "===>  TRAIN Epoch 11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0% [██████████████████████████████] 100% | ETA: 00:00:00\n",
      "Total time elapsed: 00:00:24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Epoch 11 || Run Time:   18.2 | Load Time:    6.0 || F1:  99.68 | Prec:  99.94 | Rec:  99.43 || Ex/s: 280.41\n",
      "\n",
      "===>  EVAL Epoch 11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0% [████████████████████████████] 100% | ETA: 00:00:00\n",
      "Total time elapsed: 00:00:04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Epoch 11 || Run Time:    3.0 | Load Time:    2.1 || F1:  93.53 | Prec:  93.00 | Rec:  94.07 || Ex/s: 451.71\n",
      "\n",
      "---------------------\n",
      "\n",
      "===>  TRAIN Epoch 12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0% [██████████████████████████████] 100% | ETA: 00:00:00\n",
      "Total time elapsed: 00:00:24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Epoch 12 || Run Time:   18.1 | Load Time:    6.0 || F1:  99.68 | Prec:  99.94 | Rec:  99.43 || Ex/s: 281.12\n",
      "\n",
      "===>  EVAL Epoch 12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0% [████████████████████████████] 100% | ETA: 00:00:00\n",
      "Total time elapsed: 00:00:05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Epoch 12 || Run Time:    3.0 | Load Time:    2.1 || F1:  93.63 | Prec:  93.01 | Rec:  94.26 || Ex/s: 444.12\n",
      "\n",
      "---------------------\n",
      "\n",
      "===>  TRAIN Epoch 13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0% [██████████████████████████████] 100% | ETA: 00:00:00\n",
      "Total time elapsed: 00:00:24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Epoch 13 || Run Time:   18.2 | Load Time:    6.1 || F1:  99.68 | Prec:  99.94 | Rec:  99.43 || Ex/s: 280.04\n",
      "\n",
      "===>  EVAL Epoch 13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0% [████████████████████████████] 100% | ETA: 00:00:00\n",
      "Total time elapsed: 00:00:04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Epoch 13 || Run Time:    3.0 | Load Time:    2.1 || F1:  93.64 | Prec:  92.93 | Rec:  94.35 || Ex/s: 449.66\n",
      "\n",
      "---------------------\n",
      "\n",
      "===>  TRAIN Epoch 14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0% [██████████████████████████████] 100% | ETA: 00:00:00\n",
      "Total time elapsed: 00:00:24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Epoch 14 || Run Time:   18.1 | Load Time:    6.0 || F1:  99.68 | Prec:  99.94 | Rec:  99.43 || Ex/s: 282.17\n",
      "\n",
      "===>  EVAL Epoch 14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0% [████████████████████████████] 100% | ETA: 00:00:00\n",
      "Total time elapsed: 00:00:04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Epoch 14 || Run Time:    3.0 | Load Time:    2.1 || F1:  93.64 | Prec:  92.93 | Rec:  94.35 || Ex/s: 448.74\n",
      "\n",
      "---------------------\n",
      "\n",
      "===>  TRAIN Epoch 15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0% [██████████████████████████████] 100% | ETA: 00:00:00\n",
      "Total time elapsed: 00:00:24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Epoch 15 || Run Time:   18.1 | Load Time:    6.0 || F1:  99.68 | Prec:  99.94 | Rec:  99.43 || Ex/s: 281.34\n",
      "\n",
      "===>  EVAL Epoch 15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0% [████████████████████████████] 100% | ETA: 00:00:00\n",
      "Total time elapsed: 00:00:05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Epoch 15 || Run Time:    3.0 | Load Time:    2.1 || F1:  93.68 | Prec:  93.02 | Rec:  94.35 || Ex/s: 442.66\n",
      "\n",
      "---------------------\n",
      "\n",
      "Loading best model...\n",
      "Training done.\n",
      "===>  EVAL Epoch 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0% [██████████████] 100% | ETA: 00:00:00\n",
      "Total time elapsed: 00:00:03\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Epoch 6 || Run Time:    1.6 | Load Time:    2.1 || F1:  86.73 | Prec:  90.22 | Rec:  83.51 || Ex/s: 609.79\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(86.7327, device='cuda:0')"
      ]
     },
     "execution_count": 24,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a hybrid model for DBLP-Scholar data\n",
    "model_DS = dm.MatchingModel(attr_summarizer='hybrid')\n",
    "model_DS.initialize(train_DS)  # Initilization\n",
    "\n",
    "# Train ing model on 15 epochs, batch size of 16, positive-to-negative \n",
    "# ratio to be 1:1. We save the best model (with the \n",
    "# highest F1 score on the validation set) to 'sifDiff_model.pth'.\n",
    "startTime = time.time()\n",
    "model_DS.run_train(\n",
    "    train_DS,\n",
    "    validation_DS,\n",
    "    epochs=15,\n",
    "    batch_size=16,\n",
    "    best_save_path='hybrid_Trans_DS.pth')\n",
    "executionTime_DS = (time.time() - startTime)/60\n",
    "# Evaluate the accuracy on the test data.\n",
    "model_DS.run_eval(test_DS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Q-Kfa6a_JgY4",
    "outputId": "7bf11e0f-8b95-4d4d-94ee-71a5b3aa81ad"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5240"
      ]
     },
     "execution_count": 25,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(pred['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lddkLjmRScTf",
    "outputId": "36faa64d-9ce4-4b15-a741-61da881ed7c1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11322, 6)"
      ]
     },
     "execution_count": 26,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "iqb1cvTXOLZM",
    "outputId": "f3f04466-6674-47b9-d7da-9b083a74ce7e"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Reading and processing data from \"./Dissertation_Data_2/train.csv\"\n",
      "0% [##############################] 100% | ETA: 00:00:00\n",
      "Reading and processing data from \"./Dissertation_Data_2/valid.csv\"\n",
      "0% [##############################] 100% | ETA: 00:00:00\n",
      "Reading and processing data from \"./Dissertation_Data_2/pred_cora.csv\"\n",
      "0% [##############################] 100% | ETA: 00:00:00\n",
      "Building vocabulary\n",
      "0% [##############################] 100% | ETA: 00:00:00\n",
      "Total time elapsed: 00:00:06\n",
      "\n",
      "Computing principal components\n",
      "0% [##############################] 100% | ETA: 00:00:00\n",
      "Total time elapsed: 00:00:53\n"
     ]
    }
   ],
   "source": [
    "# create data for prediction on the second model\n",
    "cand.to_csv(os.path.join('.', 'Dissertation_Data_2', 'pred_cora.csv'),index=False)\n",
    "train, validation, pred_cora = dm.data.process(\n",
    "    path=os.path.join('.', 'Dissertation_Data_2'),\n",
    "    cache='train_cache_1.pth',\n",
    "    train='train.csv',\n",
    "    validation='valid.csv',\n",
    "    test='pred_cora.csv',\n",
    "    use_magellan_convention=True,\n",
    "    ignore_columns=('ltable_id', 'rtable_id'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kUCG_NlcnE_1"
   },
   "source": [
    "# Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "x6L_UykTO65V",
    "outputId": "c57412a1-0c1f-4665-f1d3-f985e84b8870"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:py_entitymatching.io.parsers:Metadata file is not present in the given path; proceeding to read the csv file.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===>  PREDICT Epoch 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py:949: UserWarning: Using non-full backward hooks on a Module that does not take as input a single Tensor or a tuple of Tensors is deprecated and will be removed in future versions. This hook will be missing some of the grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
      "  warnings.warn(\"Using non-full backward hooks on a Module that does not take as input a \"\n",
      "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py:974: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
      "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n",
      "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py:939: UserWarning: Using non-full backward hooks on a Module that does not return a single Tensor or a tuple of Tensors is deprecated and will be removed in future versions. This hook will be missing some of the grad_output. Please use register_full_backward_hook to get the documented behavior.\n",
      "  warnings.warn(\"Using non-full backward hooks on a Module that does not return a \"\n",
      "0% [██████████████] 100% | ETA: 00:00:00\n",
      "Total time elapsed: 00:00:03\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Epoch 9 || Run Time:    1.8 | Load Time:    2.1 || F1:  81.50 | Prec:  73.84 | Rec:  90.94 || Ex/s: 588.50\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# predicting with the cora trained model on DBLP-Scholar\n",
    "train_n = em.read_csv_metadata(os.path.join('.', 'Dissertation_Data_2', 'pred_DS.csv'))\n",
    "predictions_cor_ds = model_cor.run_prediction(test_DS, output_attributes=list(test_DS.get_raw_table().columns))\n",
    "score_cor_ds = scores(executionTime_Cora, predictions_cor_ds, 15, train_n.shape[0], model = 'TransOnCora')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "pufDzDjcebiH"
   },
   "outputs": [],
   "source": [
    "prec_matrix = prec_matrix.append(score_cor_ds, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "314Hxu7yTrnb",
    "outputId": "7f82c456-e5a6-4d53-d689-107027fefd7a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===>  PREDICT Epoch 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py:949: UserWarning: Using non-full backward hooks on a Module that does not take as input a single Tensor or a tuple of Tensors is deprecated and will be removed in future versions. This hook will be missing some of the grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
      "  warnings.warn(\"Using non-full backward hooks on a Module that does not take as input a \"\n",
      "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py:974: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
      "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n",
      "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py:939: UserWarning: Using non-full backward hooks on a Module that does not return a single Tensor or a tuple of Tensors is deprecated and will be removed in future versions. This hook will be missing some of the grad_output. Please use register_full_backward_hook to get the documented behavior.\n",
      "  warnings.warn(\"Using non-full backward hooks on a Module that does not return a \"\n",
      "0% [██████████████████████████████] 100% | ETA: 00:00:00\n",
      "Total time elapsed: 00:01:52\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Epoch 6 || Run Time:   42.2 | Load Time:   71.0 || F1:  83.38 | Prec:  83.52 | Rec:  83.24 || Ex/s: 412.15\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# making predictions\n",
    "predictions_ds_cor = model_DS.run_prediction(test, output_attributes=list(test.get_raw_table().columns))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "EWiG0IXRbVJi"
   },
   "outputs": [],
   "source": [
    "score_ds_cor = scores(executionTime_DS, predictions_ds_cor, 15, cand.shape[0], model = 'TransOnDS')\n",
    "prec_matrix = prec_matrix.append(score_ds_cor, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "dfJ0YirOUJj0"
   },
   "outputs": [],
   "source": [
    "path_DL_res = os.path.join('.', 'Dissertation_Data_2', 'DL_res.csv')\n",
    "prec_matrix.to_csv(path_DL_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "bJbfjaWfUQOL"
   },
   "outputs": [],
   "source": [
    "predictions_ds_cor['match_prediction'] = predictions_ds_cor['match_score'].apply(lambda score: 1 if score >= 0.5 else 0)\n",
    "path_pred_ds_cor = os.path.join('.', 'Dissertation_Data_2', 'pred_ds_cor.csv')\n",
    "predictions_ds_cor.to_csv(path_pred_ds_cor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "id": "o4SIPtsiUQz8"
   },
   "outputs": [],
   "source": [
    "predictions_cor_ds['match_prediction'] = predictions_cor_ds['match_score'].apply(lambda score: 1 if score >= 0.5 else 0)\n",
    "path_pred_cor_ds = os.path.join('.', 'Dissertation_Data_2', 'pred_cor_ds.csv')\n",
    "predictions_cor_ds.to_csv(path_pred_cor_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "p_nd4CmSA8lA",
    "outputId": "b93b1a87-34b6-474b-f11c-be1d118a22ef"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "594396042160\n"
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "try:\n",
    "  while True:\n",
    "    i += 1\n",
    "  if not i % 1000:\n",
    "    gc.collect()\n",
    "except KeyboardInterrupt:\n",
    " print(i)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "Transfer Learning.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
